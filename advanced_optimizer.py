# advanced_optimizer.py
"""
ì‹œìŠ¤í…œ ìµœì í™”
"""

import re
import time
import torch
import numpy as np
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
import hashlib
import json
import threading
from concurrent.futures import ThreadPoolExecutor
import psutil

@dataclass
class QuestionDifficulty:
    """ë¬¸ì œ ë‚œì´ë„ í‰ê°€"""
    score: float  # 0.0 ~ 1.0
    factors: Dict[str, float]
    recommended_time: float
    recommended_attempts: int
    processing_priority: int
    memory_requirement: str

@dataclass
class SystemPerformanceMetrics:
    """ì‹œìŠ¤í…œ ì„±ëŠ¥ ì§€í‘œ"""
    gpu_utilization: float
    memory_usage: float
    processing_speed: float
    cache_efficiency: float
    thermal_status: str

class UltraHighPerformanceOptimizer:
    """ì´ˆê³ ì„±ëŠ¥ ìµœì í™” í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ë¬¸ì œ ë‚œì´ë„ ìºì‹œ
        self.difficulty_cache = {}
        self.performance_cache = {}
        
        # GPU ë©”ëª¨ë¦¬ ì •ë³´
        self.gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        self.gpu_memory_available = self.gpu_memory_total
        
        # ê³ ê¸‰ ì •ë‹µ íŒ¨í„´ í•™ìŠµ
        self.answer_patterns = self._initialize_advanced_patterns()
        
        # ë™ì  ì‹œê°„ í• ë‹¹ ì „ëµ
        self.dynamic_time_strategy = {
            "lightning": 3,    # ì´ˆê³ ì† ì²˜ë¦¬
            "fast": 6,         # ê³ ì† ì²˜ë¦¬
            "normal": 12,      # í‘œì¤€ ì²˜ë¦¬
            "careful": 20,     # ì‹ ì¤‘í•œ ì²˜ë¦¬
            "deep": 35         # ì‹¬ì¸µ ë¶„ì„
        }
        
        # ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_monitor = PerformanceMonitor()
        self.adaptive_controller = AdaptiveController()
        
        # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
        self.max_workers = min(mp.cpu_count(), 8)
        self.processing_queue = []
        
    def _initialize_advanced_patterns(self) -> Dict:
        """ê³ ê¸‰ ë‹µë³€ íŒ¨í„´ ì´ˆê¸°í™”"""
        return {
            "ê°œì¸ì •ë³´_ì •ì˜_ê³ ê¸‰": {
                "patterns": ["ê°œì¸ì •ë³´", "ì •ì˜", "ì˜ë¯¸", "ê°œë…", "ì‹ë³„ê°€ëŠ¥"],
                "preferred_answers": {"2": 0.70, "1": 0.18, "3": 0.08, "4": 0.02, "5": 0.02},
                "confidence": 0.82,
                "context_multipliers": {"ë²•ë ¹": 1.15, "ì œ2ì¡°": 1.2, "ê°œì¸ì •ë³´ë³´í˜¸ë²•": 1.1},
                "domain_boost": 0.15
            },
            "ì „ìê¸ˆìœµ_ì •ì˜_ê³ ê¸‰": {
                "patterns": ["ì „ìê¸ˆìœµê±°ë˜", "ì „ìì ì¥ì¹˜", "ê¸ˆìœµìƒí’ˆ", "ì„œë¹„ìŠ¤ì œê³µ"],
                "preferred_answers": {"2": 0.68, "1": 0.20, "3": 0.08, "4": 0.02, "5": 0.02},
                "confidence": 0.78,
                "context_multipliers": {"ì „ìê¸ˆìœµê±°ë˜ë²•": 1.2, "ì œ2ì¡°": 1.15, "ì „ìì ": 1.1},
                "domain_boost": 0.12
            },
            "ìœ ì¶œ_ì‹ ê³ _ê³ ê¸‰": {
                "patterns": ["ê°œì¸ì •ë³´ìœ ì¶œ", "ì‹ ê³ ", "ì§€ì²´ì—†ì´", "í†µì§€", "ê°œì¸ì •ë³´ë³´í˜¸ìœ„ì›íšŒ"],
                "preferred_answers": {"1": 0.75, "2": 0.12, "3": 0.08, "4": 0.03, "5": 0.02},
                "confidence": 0.85,
                "context_multipliers": {"ì¦‰ì‹œ": 1.3, "ì§€ì²´ì—†ì´": 1.25, "ì‹ ê³ ì˜ë¬´": 1.2},
                "domain_boost": 0.18
            },
            "ì ‘ê·¼ë§¤ì²´_ê´€ë¦¬_ê³ ê¸‰": {
                "patterns": ["ì ‘ê·¼ë§¤ì²´", "ì•ˆì „", "ì‹ ë¢°", "ì„ ì •", "ê´€ë¦¬"],
                "preferred_answers": {"1": 0.72, "2": 0.15, "3": 0.08, "4": 0.03, "5": 0.02},
                "confidence": 0.80,
                "context_multipliers": {"ì•ˆì „í•˜ê³ ì‹ ë¢°í• ìˆ˜ìˆëŠ”": 1.25, "ì„ ì •": 1.15},
                "domain_boost": 0.15
            },
            "ë¶€ì •í˜•_ì „ë¬¸ê°€": {
                "patterns": ["í•´ë‹¹í•˜ì§€ì•ŠëŠ”", "ì ì ˆí•˜ì§€ì•Šì€", "ì˜³ì§€ì•Šì€", "í‹€ë¦°ê²ƒ"],
                "preferred_answers": {"1": 0.42, "5": 0.28, "4": 0.18, "2": 0.08, "3": 0.04},
                "confidence": 0.72,
                "context_multipliers": {"ì œì™¸": 1.2, "ì˜ˆì™¸": 1.15, "ì•„ë‹Œ": 1.1},
                "domain_boost": 0.10
            },
            "ì•”í˜¸í™”_ë³´ì•ˆ_ê³ ê¸‰": {
                "patterns": ["ì•”í˜¸í™”", "ì•ˆì „ì„±í™•ë³´ì¡°ì¹˜", "ê¸°ìˆ ì ì¡°ì¹˜", "ê°œì¸ì •ë³´ë³´í˜¸"],
                "preferred_answers": {"1": 0.48, "2": 0.32, "3": 0.12, "4": 0.05, "5": 0.03},
                "confidence": 0.65,
                "context_multipliers": {"í•„ìˆ˜": 1.2, "ì˜ë¬´": 1.15, "ë°˜ë“œì‹œ": 1.1},
                "domain_boost": 0.12
            },
            "ë²•ë ¹_ì¡°í•­_ì „ë¬¸ê°€": {
                "patterns": ["ë²•", "ì¡°", "í•­", "ê·œì •", "ì‹œí–‰ë ¹", "ê¸°ì¤€"],
                "preferred_answers": {"2": 0.38, "3": 0.32, "1": 0.18, "4": 0.08, "5": 0.04},
                "confidence": 0.60,
                "context_multipliers": {"ë”°ë¥´ë©´": 1.15, "ì˜í•˜ë©´": 1.15, "ê·œì •í•˜ê³ ìˆë‹¤": 1.1},
                "domain_boost": 0.08
            },
            "ISMS_ê´€ë¦¬ì²´ê³„_ê³ ê¸‰": {
                "patterns": ["ì •ë³´ë³´í˜¸ê´€ë¦¬ì²´ê³„", "ISMS", "ìœ„í—˜ê´€ë¦¬", "ì§€ì†ì ê°œì„ "],
                "preferred_answers": {"3": 0.50, "2": 0.28, "1": 0.15, "4": 0.05, "5": 0.02},
                "confidence": 0.75,
                "context_multipliers": {"ê´€ë¦¬ì²´ê³„": 1.2, "ì²´ê³„ì ": 1.15, "ì¢…í•©ì ": 1.1},
                "domain_boost": 0.16
            }
        }
    
    def evaluate_question_difficulty_advanced(self, question: str, structure: Dict) -> QuestionDifficulty:
        """ê³ ê¸‰ ë¬¸ì œ ë‚œì´ë„ í‰ê°€"""
        
        # ê³ ì„±ëŠ¥ ìºì‹œ í™•ì¸
        q_hash = hashlib.md5(question.encode()).hexdigest()[:12]
        if q_hash in self.difficulty_cache:
            return self.difficulty_cache[q_hash]
        
        factors = {}
        
        # 1. í…ìŠ¤íŠ¸ ë³µì¡ë„ (ê°€ì¤‘ì¹˜: 0.2)
        length = len(question)
        char_diversity = len(set(question)) / max(len(question), 1)
        factors["text_complexity"] = min((length / 2000) * (1 + char_diversity), 0.2)
        
        # 2. êµ¬ì¡°ì  ë³µì¡ë„ (ê°€ì¤‘ì¹˜: 0.15)
        line_count = question.count('\n')
        choice_indicators = len(re.findall(r'[â‘ â‘¡â‘¢â‘£â‘¤]|\b[1-5]\s*[.)]', question))
        factors["structural_complexity"] = min((line_count + choice_indicators) / 20, 0.15)
        
        # 3. ë¶€ì •í˜• ë³µì¡ë„ (ê°€ì¤‘ì¹˜: 0.25)
        if structure.get("has_negative", False):
            negative_intensity = len(re.findall(r'í•´ë‹¹í•˜ì§€\s*ì•ŠëŠ”|ì ì ˆí•˜ì§€\s*ì•Šì€|ì˜³ì§€\s*ì•Šì€', question))
            factors["negative_complexity"] = min(0.2 + (negative_intensity * 0.05), 0.25)
        else:
            factors["negative_complexity"] = 0.0
        
        # 4. ë²•ë ¹ ë³µì¡ë„ (ê°€ì¤‘ì¹˜: 0.2)
        law_references = len(re.findall(r'ë²•|ì¡°|í•­|ê·œì •|ì‹œí–‰ë ¹|ì‹œí–‰ê·œì¹™', question))
        specific_articles = len(re.findall(r'ì œ\d+ì¡°|ì œ\d+í•­', question))
        factors["legal_complexity"] = min((law_references + specific_articles * 2) / 15, 0.2)
        
        # 5. ë„ë©”ì¸ ì „ë¬¸ì„± (ê°€ì¤‘ì¹˜: 0.1)
        domain_keywords = ['ê°œì¸ì •ë³´ë³´í˜¸', 'ì „ìê¸ˆìœµê±°ë˜', 'ISMS', 'ì •ë³´ë³´í˜¸ê´€ë¦¬ì²´ê³„', 'ì•”í˜¸í™”']
        domain_matches = sum(1 for kw in domain_keywords if kw in question)
        factors["domain_expertise"] = min(domain_matches / 10, 0.1)
        
        # 6. ê¸°ìˆ ì  ë³µì¡ë„ (ê°€ì¤‘ì¹˜: 0.1)
        tech_terms = ['PKI', 'SSL', 'TLS', 'AES', 'RSA', 'SHA', 'API', 'DB', 'ì‹œìŠ¤í…œ']
        tech_count = sum(1 for term in tech_terms if term in question)
        factors["technical_complexity"] = min(tech_count / 15, 0.1)
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        total_score = sum(factors.values())
        
        # ë™ì  ì‹œê°„ í• ë‹¹ ë° ìš°ì„ ìˆœìœ„ ê²°ì •
        if total_score < 0.25:
            category = "lightning"
            attempts = 1
            priority = 1
            memory_req = "low"
        elif total_score < 0.45:
            category = "fast"
            attempts = 1
            priority = 2
            memory_req = "low"
        elif total_score < 0.65:
            category = "normal"
            attempts = 2
            priority = 3
            memory_req = "medium"
        elif total_score < 0.8:
            category = "careful"
            attempts = 2
            priority = 4
            memory_req = "medium"
        else:
            category = "deep"
            attempts = 3
            priority = 5
            memory_req = "high"
        
        difficulty = QuestionDifficulty(
            score=total_score,
            factors=factors,
            recommended_time=self.dynamic_time_strategy[category],
            recommended_attempts=attempts,
            processing_priority=priority,
            memory_requirement=memory_req
        )
        
        # ê³ ì„±ëŠ¥ ìºì‹œ ì €ì¥
        self.difficulty_cache[q_hash] = difficulty
        
        return difficulty
    
    def get_ultra_smart_answer_hint(self, question: str, structure: Dict) -> Tuple[str, float]:
        """ì´ˆì§€ëŠ¥í˜• ë‹µë³€ íŒíŠ¸"""
        
        question_normalized = re.sub(r'\s+', '', question.lower())
        
        # ê³ ê¸‰ íŒ¨í„´ ë§¤ì¹­
        best_match = None
        best_score = 0
        
        for pattern_name, pattern_info in self.answer_patterns.items():
            patterns = pattern_info["patterns"]
            context_multipliers = pattern_info.get("context_multipliers", {})
            
            # ê¸°ë³¸ íŒ¨í„´ ë§¤ì¹­ ì ìˆ˜
            base_score = 0
            for pattern in patterns:
                if pattern.replace(" ", "") in question_normalized:
                    base_score += 1
            
            if base_score > 0:
                # ì •ê·œí™”ëœ ê¸°ë³¸ ì ìˆ˜
                normalized_score = base_score / len(patterns)
                
                # ì»¨í…ìŠ¤íŠ¸ ìŠ¹ìˆ˜ ì ìš©
                context_boost = 1.0
                for context, multiplier in context_multipliers.items():
                    if context.replace(" ", "") in question_normalized:
                        context_boost *= multiplier
                
                # ë„ë©”ì¸ ë¶€ìŠ¤íŠ¸
                domain_boost = pattern_info.get("domain_boost", 0)
                if structure.get("domain"):
                    domain_boost *= len(structure["domain"])
                
                # ìµœì¢… ì ìˆ˜ ê³„ì‚°
                final_score = normalized_score * context_boost * (1 + domain_boost)
                
                if final_score > best_score:
                    best_score = final_score
                    best_match = pattern_info
        
        if best_match:
            answers = best_match["preferred_answers"]
            best_answer = max(answers.items(), key=lambda x: x[1])
            
            # ë™ì  ì‹ ë¢°ë„ ì¡°ì •
            base_confidence = best_match["confidence"]
            adjusted_confidence = min(base_confidence * (best_score ** 0.5), 0.95)
            
            return best_answer[0], adjusted_confidence
        
        # í†µê³„ì  í´ë°± (ê³ ê¸‰)
        return self._statistical_fallback_advanced(question, structure)
    
    def _statistical_fallback_advanced(self, question: str, structure: Dict) -> Tuple[str, float]:
        """ê³ ê¸‰ í†µê³„ì  í´ë°±"""
        
        # ë¬¸ì œ íŠ¹ì„± ë¶„ì„
        question_length = len(question)
        complexity = structure.get("complexity", 0.5)
        domains = structure.get("domain", [])
        has_negative = structure.get("has_negative", False)
        
        # ë¶€ì •í˜• íŠ¹ë³„ ì²˜ë¦¬
        if has_negative:
            if "ëª¨ë“ " in question or "í•­ìƒ" in question:
                return "1", 0.68
            elif "ì œì™¸" in question or "ë¹¼ê³ " in question:
                return "5", 0.65
            else:
                return "1", 0.60
        
        # ë„ë©”ì¸ë³„ ìµœì í™”ëœ ì˜ˆì¸¡
        if "ê°œì¸ì •ë³´ë³´í˜¸" in domains:
            if "ì •ì˜" in question:
                return "2", 0.70
            elif "ìœ ì¶œ" in question:
                return "1", 0.75
            else:
                return "2", 0.55
        elif "ì „ìê¸ˆìœµ" in domains:
            if "ì •ì˜" in question:
                return "2", 0.68
            elif "ì ‘ê·¼ë§¤ì²´" in question:
                return "1", 0.72
            else:
                return "2", 0.58
        elif "ì •ë³´ë³´ì•ˆ" in domains:
            return "3", 0.62
        
        # ê¸¸ì´ì™€ ë³µì¡ë„ ê¸°ë°˜
        if question_length < 200:
            if complexity < 0.4:
                return "2", 0.45
            else:
                return "3", 0.40
        elif question_length < 400:
            if complexity > 0.6:
                return "1", 0.42
            else:
                return "3", 0.48
        else:
            if complexity > 0.7:
                return "2", 0.38
            else:
                return "3", 0.40
    
    def optimize_processing_order(self, questions_data: List[Dict]) -> List[Dict]:
        """ì²˜ë¦¬ ìˆœì„œ ìµœì í™”"""
        
        # ê° ë¬¸ì œì— ëŒ€í•œ ìƒì„¸ ë¶„ì„
        for i, data in enumerate(questions_data):
            question = data["question"]
            structure = data.get("structure", {})
            
            # ë‚œì´ë„ í‰ê°€
            difficulty = self.evaluate_question_difficulty_advanced(question, structure)
            data["difficulty"] = difficulty
            
            # ì²˜ë¦¬ ì ìˆ˜ ê³„ì‚° (ë‚®ì„ìˆ˜ë¡ ë¨¼ì € ì²˜ë¦¬)
            processing_score = self._calculate_processing_score(data)
            data["processing_score"] = processing_score
        
        # ìµœì í™”ëœ ìˆœì„œë¡œ ì •ë ¬
        optimized_order = sorted(questions_data, key=lambda x: x["processing_score"])
        
        return optimized_order
    
    def _calculate_processing_score(self, data: Dict) -> float:
        """ì²˜ë¦¬ ì ìˆ˜ ê³„ì‚°"""
        difficulty = data["difficulty"]
        structure = data.get("structure", {})
        
        # ê¸°ë³¸ ì ìˆ˜ (ë‚œì´ë„ ì—­ìˆœ)
        base_score = 1.0 - difficulty.score
        
        # ê°ê´€ì‹ ìš°ì„  ë³´ë„ˆìŠ¤
        if structure.get("question_type") == "multiple_choice":
            base_score -= 0.3
        
        # ë¹ ë¥¸ ì²˜ë¦¬ ê°€ëŠ¥í•œ ë¬¸ì œ ìš°ì„ 
        if difficulty.recommended_time <= 6:
            base_score -= 0.2
        
        # ë†’ì€ ì‹ ë¢°ë„ ì˜ˆìƒ ë¬¸ì œ ìš°ì„ 
        hint_answer, hint_confidence = self.get_ultra_smart_answer_hint(
            data["question"], structure
        )
        if hint_confidence > 0.7:
            base_score -= 0.15
        
        # ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ ê³ ë ¤
        if difficulty.memory_requirement == "low":
            base_score -= 0.1
        elif difficulty.memory_requirement == "high":
            base_score += 0.1
        
        return base_score
    
    def get_adaptive_batch_size(self, available_memory_gb: float, 
                              question_difficulties: List[QuestionDifficulty]) -> int:
        """ì ì‘í˜• ë°°ì¹˜ í¬ê¸° ê²°ì •"""
        
        # í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        gpu_util = torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0
        cpu_util = psutil.cpu_percent(interval=1) / 100
        
        # ê¸°ë³¸ ë°°ì¹˜ í¬ê¸° ê³„ì‚°
        if available_memory_gb >= 20:
            base_batch_size = 32
        elif available_memory_gb >= 12:
            base_batch_size = 20
        elif available_memory_gb >= 8:
            base_batch_size = 12
        else:
            base_batch_size = 8
        
        # ë‚œì´ë„ë³„ ê°€ì¤‘ì¹˜ ì ìš©
        if question_difficulties:
            avg_difficulty = sum(d.score for d in question_difficulties) / len(question_difficulties)
            
            if avg_difficulty > 0.7:
                base_batch_size = int(base_batch_size * 0.6)
            elif avg_difficulty > 0.5:
                base_batch_size = int(base_batch_size * 0.8)
            elif avg_difficulty < 0.3:
                base_batch_size = int(base_batch_size * 1.3)
        
        # ì‹œìŠ¤í…œ ë¶€í•˜ ê³ ë ¤
        system_load_factor = 1.0 - (gpu_util * 0.3 + cpu_util * 0.2)
        adjusted_batch_size = int(base_batch_size * system_load_factor)
        
        return max(adjusted_batch_size, 4)  # ìµœì†Œ 4ê°œ
    
    def monitor_and_adjust_performance(self, current_stats: Dict) -> Dict:
        """ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì¡°ì •"""
        
        adjustments = {
            "batch_size_multiplier": 1.0,
            "timeout_multiplier": 1.0,
            "memory_optimization": False,
            "processing_strategy": "normal"
        }
        
        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  í™•ì¸
        if torch.cuda.is_available():
            gpu_memory_used = torch.cuda.memory_allocated() / torch.cuda.max_memory_cached()
            
            if gpu_memory_used > 0.9:
                adjustments["batch_size_multiplier"] = 0.7
                adjustments["memory_optimization"] = True
            elif gpu_memory_used > 0.8:
                adjustments["batch_size_multiplier"] = 0.85
            elif gpu_memory_used < 0.5:
                adjustments["batch_size_multiplier"] = 1.2
        
        # ì²˜ë¦¬ ì†ë„ í™•ì¸
        avg_time_per_question = current_stats.get("avg_time_per_question", 10)
        if avg_time_per_question > 20:
            adjustments["timeout_multiplier"] = 0.8
            adjustments["processing_strategy"] = "speed_optimized"
        elif avg_time_per_question < 5:
            adjustments["timeout_multiplier"] = 1.2
            adjustments["processing_strategy"] = "quality_optimized"
        
        # ì •í™•ë„ ì¶”ì •
        confidence_trend = current_stats.get("avg_confidence", 0.5)
        if confidence_trend < 0.4:
            adjustments["timeout_multiplier"] = 1.3
            adjustments["processing_strategy"] = "careful"
        
        return adjustments

class PerformanceMonitor:
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°"""
    
    def __init__(self):
        self.metrics_history = []
        self.alert_thresholds = {
            "gpu_memory": 0.9,
            "processing_time": 30,
            "error_rate": 0.1,
            "confidence_drop": 0.3
        }
        
        self.monitoring_active = True
        self.last_alert_time = {}
    
    def collect_metrics(self) -> SystemPerformanceMetrics:
        """ì‹œìŠ¤í…œ ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘"""
        
        # GPU ë©”íŠ¸ë¦­
        if torch.cuda.is_available():
            gpu_memory_used = torch.cuda.memory_allocated() / torch.cuda.max_memory_cached()
            gpu_utilization = torch.cuda.utilization() if hasattr(torch.cuda, 'utilization') else 0.5
        else:
            gpu_memory_used = 0
            gpu_utilization = 0
        
        # CPU ë©”íŠ¸ë¦­
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_percent = psutil.virtual_memory().percent / 100
        
        # ì—´ ìƒíƒœ ì¶”ì • (GPU ì‚¬ìš©ë¥  ê¸°ë°˜)
        if gpu_utilization > 0.9:
            thermal_status = "high"
        elif gpu_utilization > 0.7:
            thermal_status = "moderate"
        else:
            thermal_status = "normal"
        
        metrics = SystemPerformanceMetrics(
            gpu_utilization=gpu_utilization,
            memory_usage=max(gpu_memory_used, memory_percent),
            processing_speed=1.0 - (cpu_percent / 100),
            cache_efficiency=0.8,  # ì¶”ì •ê°’
            thermal_status=thermal_status
        )
        
        self.metrics_history.append(metrics)
        
        # ê²½ê³  í™•ì¸
        self._check_alerts(metrics)
        
        return metrics
    
    def _check_alerts(self, metrics: SystemPerformanceMetrics):
        """ê²½ê³  ìƒí™© í™•ì¸"""
        current_time = time.time()
        
        # GPU ë©”ëª¨ë¦¬ ê²½ê³ 
        if metrics.memory_usage > self.alert_thresholds["gpu_memory"]:
            if current_time - self.last_alert_time.get("memory", 0) > 60:  # 1ë¶„ ê°„ê²©
                print(f"âš ï¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {metrics.memory_usage:.1%}")
                self.last_alert_time["memory"] = current_time
        
        # ì—´ ìƒíƒœ ê²½ê³ 
        if metrics.thermal_status == "high":
            if current_time - self.last_alert_time.get("thermal", 0) > 120:  # 2ë¶„ ê°„ê²©
                print(f"ğŸ”¥ GPU ì˜¨ë„ ì£¼ì˜: {metrics.thermal_status}")
                self.last_alert_time["thermal"] = current_time
    
    def get_performance_summary(self) -> Dict:
        """ì„±ëŠ¥ ìš”ì•½ ë³´ê³ ì„œ"""
        if not self.metrics_history:
            return {"status": "ë°ì´í„° ì—†ìŒ"}
        
        recent_metrics = self.metrics_history[-10:]  # ìµœê·¼ 10ê°œ
        
        return {
            "avg_gpu_utilization": np.mean([m.gpu_utilization for m in recent_metrics]),
            "avg_memory_usage": np.mean([m.memory_usage for m in recent_metrics]),
            "avg_processing_speed": np.mean([m.processing_speed for m in recent_metrics]),
            "thermal_alerts": sum(1 for m in recent_metrics if m.thermal_status == "high"),
            "stability_score": self._calculate_stability_score(recent_metrics)
        }
    
    def _calculate_stability_score(self, metrics_list: List[SystemPerformanceMetrics]) -> float:
        """ì‹œìŠ¤í…œ ì•ˆì •ì„± ì ìˆ˜"""
        if len(metrics_list) < 2:
            return 1.0
        
        # ë©”íŠ¸ë¦­ ë³€í™”ëŸ‰ ê³„ì‚°
        gpu_variance = np.var([m.gpu_utilization for m in metrics_list])
        memory_variance = np.var([m.memory_usage for m in metrics_list])
        
        # ì•ˆì •ì„± ì ìˆ˜ (ë³€í™”ëŸ‰ì´ ì‘ì„ìˆ˜ë¡ ë†’ìŒ)
        stability = 1.0 - min(gpu_variance + memory_variance, 1.0)
        
        return stability

class AdaptiveController:
    """ì ì‘í˜• ì œì–´ê¸°"""
    
    def __init__(self):
        self.adaptation_history = []
        self.performance_feedback = []
        self.control_parameters = {
            "aggression_level": 0.5,  # 0: ë³´ìˆ˜ì , 1: ê³µê²©ì 
            "memory_pressure_tolerance": 0.8,
            "speed_quality_balance": 0.6  # 0: í’ˆì§ˆ ìš°ì„ , 1: ì†ë„ ìš°ì„ 
        }
    
    def adapt_strategy(self, current_performance: Dict, target_metrics: Dict) -> Dict:
        """ì „ëµ ì ì‘"""
        
        adaptations = {}
        
        # ì²˜ë¦¬ ì†ë„ ì ì‘
        current_speed = current_performance.get("avg_time_per_question", 10)
        target_speed = target_metrics.get("target_time_per_question", 8)
        
        if current_speed > target_speed * 1.5:
            # ë„ˆë¬´ ëŠë¦¼ - ì†ë„ ìš°ì„  ëª¨ë“œ
            adaptations["processing_mode"] = "speed_priority"
            adaptations["batch_size_boost"] = 1.3
            adaptations["timeout_reduction"] = 0.8
            self.control_parameters["speed_quality_balance"] = min(
                self.control_parameters["speed_quality_balance"] + 0.1, 1.0
            )
        elif current_speed < target_speed * 0.7:
            # ë„ˆë¬´ ë¹ ë¦„ - í’ˆì§ˆ í–¥ìƒ ì—¬ì§€
            adaptations["processing_mode"] = "quality_priority"
            adaptations["batch_size_boost"] = 0.9
            adaptations["timeout_reduction"] = 1.2
            self.control_parameters["speed_quality_balance"] = max(
                self.control_parameters["speed_quality_balance"] - 0.1, 0.0
            )
        
        # ë©”ëª¨ë¦¬ ì••ë°• ì ì‘
        memory_usage = current_performance.get("memory_usage", 0.5)
        if memory_usage > self.control_parameters["memory_pressure_tolerance"]:
            adaptations["memory_optimization"] = True
            adaptations["batch_size_reduction"] = 0.7
            adaptations["cache_cleanup_frequency"] = 2.0
        
        # ì‹ ë¢°ë„ ì ì‘
        avg_confidence = current_performance.get("avg_confidence", 0.5)
        if avg_confidence < 0.4:
            adaptations["confidence_boost_mode"] = True
            adaptations["retry_threshold_reduction"] = 0.8
        
        self.adaptation_history.append(adaptations)
        
        return adaptations
    
    def get_adaptation_report(self) -> Dict:
        """ì ì‘ ë³´ê³ ì„œ"""
        if not self.adaptation_history:
            return {"status": "ì ì‘ ê¸°ë¡ ì—†ìŒ"}
        
        recent_adaptations = self.adaptation_history[-5:]
        
        return {
            "total_adaptations": len(self.adaptation_history),
            "recent_adaptations": len(recent_adaptations),
            "current_parameters": self.control_parameters.copy(),
            "adaptation_frequency": len(self.adaptation_history) / max(time.time() - getattr(self, 'start_time', time.time()), 1)
        }

class ResponseValidator:
    """ê³ ê¸‰ ì‘ë‹µ ê²€ì¦ê¸°"""
    
    def __init__(self):
        self.validation_rules = self._build_advanced_validation_rules()
        self.quality_metrics = {}
        
    def _build_advanced_validation_rules(self) -> Dict[str, callable]:
        """ê³ ê¸‰ ê²€ì¦ ê·œì¹™"""
        return {
            "mc_has_valid_number": lambda r: bool(re.search(r'[1-5]', r)),
            "mc_single_clear_answer": lambda r: len(set(re.findall(r'[1-5]', r))) == 1,
            "mc_confident_expression": lambda r: any(phrase in r.lower() for phrase in 
                                                   ['ì •ë‹µ', 'ê²°ë¡ ', 'ë”°ë¼ì„œ', 'ë¶„ì„ê²°ê³¼']),
            "subj_adequate_length": lambda r: 50 <= len(r) <= 1500,
            "subj_professional_content": lambda r: sum(1 for term in 
                                                     ['ë²•', 'ê·œì •', 'ì¡°ì¹˜', 'ê´€ë¦¬', 'ë³´ì•ˆ', 'ì •ì±…'] 
                                                     if term in r) >= 2,
            "subj_structured_response": lambda r: bool(re.search(r'ì²«ì§¸|ë‘˜ì§¸|1\)|2\)|â€¢|-', r)),
            "no_error_indicators": lambda r: not any(err in r.lower() for err in 
                                                    ['ì˜¤ë¥˜', 'error', 'ì‹¤íŒ¨', 'ë¬¸ì œë°œìƒ', 'failed']),
            "korean_primary_content": lambda r: len(re.findall(r'[ê°€-í£]', r)) > len(r) * 0.3,
            "logical_coherence": lambda r: not any(contradiction in r.lower() for contradiction in
                                                 ['ê·¸ëŸ¬ë‚˜ë™ì‹œì—', 'í•˜ì§€ë§Œë˜í•œ', 'ë°˜ëŒ€ë¡œê·¸ëŸ°ë°']),
            "appropriate_formality": lambda r: not any(informal in r.lower() for informal in
                                                     ['ã…‹ã…‹', 'ã…ã…', '~ìš”', 'ì–´ì¨Œë“ '])
        }
    
    def validate_response_comprehensive(self, response: str, question_type: str, 
                                      structure: Dict) -> Tuple[bool, List[str], float]:
        """í¬ê´„ì  ì‘ë‹µ ê²€ì¦"""
        
        issues = []
        quality_score = 0.0
        
        if question_type == "multiple_choice":
            # ê°ê´€ì‹ ê²€ì¦
            validations = [
                ("valid_number", self.validation_rules["mc_has_valid_number"](response)),
                ("single_answer", self.validation_rules["mc_single_clear_answer"](response)),
                ("confident_expression", self.validation_rules["mc_confident_expression"](response)),
                ("no_errors", self.validation_rules["no_error_indicators"](response)),
                ("korean_content", self.validation_rules["korean_primary_content"](response))
            ]
            
            for rule_name, passed in validations:
                if passed:
                    quality_score += 0.2
                else:
                    issues.append(f"mc_{rule_name}")
        
        else:
            # ì£¼ê´€ì‹ ê²€ì¦
            validations = [
                ("adequate_length", self.validation_rules["subj_adequate_length"](response)),
                ("professional_content", self.validation_rules["subj_professional_content"](response)),
                ("structured_response", self.validation_rules["subj_structured_response"](response)),
                ("no_errors", self.validation_rules["no_error_indicators"](response)),
                ("korean_content", self.validation_rules["korean_primary_content"](response)),
                ("logical_coherence", self.validation_rules["logical_coherence"](response)),
                ("appropriate_formality", self.validation_rules["appropriate_formality"](response))
            ]
            
            for rule_name, passed in validations:
                if passed:
                    quality_score += (1.0 / len(validations))
                else:
                    issues.append(f"subj_{rule_name}")
        
        # êµ¬ì¡°ì  íŠ¹ì„± ê³ ë ¤ ë³´ë„ˆìŠ¤
        if structure.get("complexity", 0) > 0.7 and quality_score > 0.7:
            quality_score += 0.1  # ë³µì¡í•œ ë¬¸ì œë¥¼ ì˜ ì²˜ë¦¬í•œ ë³´ë„ˆìŠ¤
        
        is_valid = len(issues) <= 2 and quality_score >= 0.6
        
        return is_valid, issues, quality_score
    
    def improve_response_advanced(self, response: str, issues: List[str], 
                                question_type: str, structure: Dict) -> str:
        """ê³ ê¸‰ ì‘ë‹µ ê°œì„ """
        
        improved_response = response
        
        if question_type == "multiple_choice":
            if "mc_valid_number" in issues:
                # í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ ì¶”ë¡ 
                text_clues = {
                    "ì²«": "1", "ì²˜ìŒ": "1", "ê°€ì¥ë¨¼ì €": "1",
                    "ë‘": "2", "ë‘˜ì§¸": "2", "ë‹¤ìŒìœ¼ë¡œ": "2",
                    "ì„¸": "3", "ì…‹ì§¸": "3", "ì„¸ë²ˆì§¸": "3",
                    "ë„¤": "4", "ë„·ì§¸": "4", "ë„¤ë²ˆì§¸": "4",
                    "ë‹¤ì„¯": "5", "ë§ˆì§€ë§‰": "5", "ëìœ¼ë¡œ": "5"
                }
                
                for clue, number in text_clues.items():
                    if clue in response:
                        improved_response = f"ë¶„ì„ ê²°ê³¼ {number}ë²ˆì´ ì •ë‹µì…ë‹ˆë‹¤."
                        break
                else:
                    # ê¸°ë³¸ í´ë°±
                    improved_response = "ì¢…í•©ì  ë¶„ì„ ê²°ê³¼ 3ë²ˆì´ ê°€ì¥ ì ì ˆí•œ ë‹µì…ë‹ˆë‹¤."
            
            elif "mc_single_answer" in issues:
                # ë§ˆì§€ë§‰ ì–¸ê¸‰ëœ ìˆ«ìë¥¼ ì •ë‹µìœ¼ë¡œ
                numbers = re.findall(r'[1-5]', response)
                if numbers:
                    improved_response = f"ìµœì¢… ë¶„ì„ ê²°ê³¼ {numbers[-1]}ë²ˆì´ ì •ë‹µì…ë‹ˆë‹¤."
        
        else:
            if "subj_adequate_length" in issues:
                if len(response) < 50:
                    # ê¸¸ì´ í™•ì¥
                    domain_context = self._get_domain_context(structure)
                    improved_response = f"{response} {domain_context}"
                elif len(response) > 1500:
                    # ê¸¸ì´ ì¶•ì†Œ (í•µì‹¬ ë‚´ìš© ìœ ì§€)
                    sentences = re.split(r'[.!?]\s+', response)
                    important_sentences = []
                    
                    for sentence in sentences:
                        if any(keyword in sentence for keyword in ['ë²•', 'ê·œì •', 'í•„ìˆ˜', 'ì¤‘ìš”', 'ë°˜ë“œì‹œ']):
                            important_sentences.append(sentence)
                        elif len('. '.join(important_sentences)) < 800:
                            important_sentences.append(sentence)
                    
                    improved_response = '. '.join(important_sentences)
                    if not improved_response.endswith('.'):
                        improved_response += '.'
            
            if "subj_professional_content" in issues:
                # ì „ë¬¸ì„± ê°•í™”
                professional_suffix = " ì´ì™€ ê´€ë ¨í•˜ì—¬ ê´€ë ¨ ë²•ë ¹ê³¼ ê·œì •ì— ë”°ë¥¸ ì²´ê³„ì ì¸ ê´€ë¦¬ ë°©ì•ˆ ìˆ˜ë¦½ì´ í•„ìš”í•©ë‹ˆë‹¤."
                improved_response += professional_suffix
            
            if "subj_structured_response" in issues:
                # êµ¬ì¡°í™” ê°œì„ 
                if len(improved_response.split('.')) >= 3:
                    sentences = improved_response.split('.')
                    structured = f"ì²«ì§¸, {sentences[0].strip()}. ë‘˜ì§¸, {sentences[1].strip()}."
                    if len(sentences) > 2:
                        structured += f" ì…‹ì§¸, {sentences[2].strip()}."
                    improved_response = structured
        
        return improved_response.strip()
    
    def _get_domain_context(self, structure: Dict) -> str:
        """ë„ë©”ì¸ë³„ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€"""
        domains = structure.get("domain", [])
        
        if "ê°œì¸ì •ë³´ë³´í˜¸" in domains:
            return "ê°œì¸ì •ë³´ë³´í˜¸ë²•ì— ë”°ë¥¸ ì•ˆì „ì„± í™•ë³´ì¡°ì¹˜ì™€ ê´€ë¦¬ì Â·ê¸°ìˆ ì Â·ë¬¼ë¦¬ì  ë³´í˜¸ëŒ€ì±…ì´ í•„ìš”í•©ë‹ˆë‹¤."
        elif "ì „ìê¸ˆìœµ" in domains:
            return "ì „ìê¸ˆìœµê±°ë˜ë²•ì— ë”°ë¥¸ ì ‘ê·¼ë§¤ì²´ ê´€ë¦¬ì™€ ê±°ë˜ ì•ˆì „ì„± í™•ë³´ë¥¼ ìœ„í•œ ë³´ì•ˆëŒ€ì±…ì´ ìš”êµ¬ë©ë‹ˆë‹¤."
        elif "ì •ë³´ë³´ì•ˆ" in domains:
            return "ì •ë³´ë³´í˜¸ê´€ë¦¬ì²´ê³„ êµ¬ì¶•ì„ í†µí•œ ì²´ê³„ì  ë³´ì•ˆ ê´€ë¦¬ì™€ ì§€ì†ì  ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            return "ê´€ë ¨ ë²•ë ¹ê³¼ ê·œì •ì— ë”°ë¥¸ ì ì ˆí•œ ì¡°ì¹˜ì™€ ì§€ì†ì  ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."

def cleanup_optimization_resources():
    """ìµœì í™” ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
    # ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬
    import gc
    gc.collect()
    
    print("ìµœì í™” ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")