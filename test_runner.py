# test_runner.py

"""
í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸° - ì£¼ê´€ì‹ ë‹µë³€ ìƒì„± íŠ¹í™” í…ŒìŠ¤íŠ¸
- ì£¼ê´€ì‹ ë‹µë³€ í’ˆì§ˆ ì§‘ì¤‘ í…ŒìŠ¤íŠ¸
- í…œí”Œë¦¿ í™œìš© íš¨ê³¼ì„± ê²€ì¦
- ì˜ë„ ë¶„ì„ ì •í™•ë„ ì¸¡ì •
- ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ìƒì„± í™•ì¸
- í’ˆì§ˆ í–¥ìƒ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import os
import sys
from pathlib import Path
import time

# í˜„ì¬ ë””ë ‰í† ë¦¬ ì„¤ì •
current_dir = Path(__file__).parent.absolute()
sys.path.append(str(current_dir))

# ì„¤ì • íŒŒì¼ import
from config import FILE_VALIDATION, DEFAULT_FILES, print_config_summary, relax_quality_standards
from inference import FinancialAIInference


def run_enhanced_subjective_test(test_size: int = None, verbose: bool = True):
    """ì£¼ê´€ì‹ ë‹µë³€ ìƒì„± íŠ¹í™” í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""

    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ í¬ê¸° ì„¤ì •
    if test_size is None:
        test_size = 20  # ì£¼ê´€ì‹ íŠ¹í™” í…ŒìŠ¤íŠ¸ëŠ” ë” ì ì€ ìˆ˜ë¡œ

    print(f"\n=== ì£¼ê´€ì‹ ë‹µë³€ ìƒì„± íŠ¹í™” í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    print(f"í…ŒìŠ¤íŠ¸ í¬ê¸°: {test_size}ê°œ ë¬¸í•­")
    print("ì£¼ìš” ê²€ì¦ í•­ëª©:")
    print("- í…œí”Œë¦¿ í™œìš© íš¨ê³¼ì„±")
    print("- ì˜ë„ ë¶„ì„ ì •í™•ë„")
    print("- ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ìƒì„±")
    print("- ë°˜ë³µ íŒ¨í„´ ë°©ì§€")
    print("- ë‹µë³€ í’ˆì§ˆ ì¼ê´€ì„±")

    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    test_file = DEFAULT_FILES["test_file"]
    submission_file = DEFAULT_FILES["submission_file"]

    for file_path in [test_file, submission_file]:
        if not os.path.exists(file_path):
            print(f"ì˜¤ë¥˜: {file_path} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return False

    engine = None
    try:
        # ì„¤ì • ìš”ì•½ ì¶œë ¥
        if verbose:
            print_config_summary()

        # AI ì—”ì§„ ì´ˆê¸°í™”
        print("\nì£¼ê´€ì‹ íŠ¹í™” AI ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
        engine = FinancialAIInference(verbose=verbose)

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        import pandas as pd

        test_df = pd.read_csv(test_file, encoding=FILE_VALIDATION["encoding"])
        submission_df = pd.read_csv(
            submission_file, encoding=FILE_VALIDATION["encoding"]
        )

        print(f"ì „ì²´ ë°ì´í„°: {len(test_df)}ê°œ ë¬¸í•­")

        # ì£¼ê´€ì‹ ë¬¸í•­ ìš°ì„  í•„í„°ë§
        subjective_questions = []
        print("\nì£¼ê´€ì‹ ë¬¸í•­ í•„í„°ë§ ì¤‘...")
        
        for idx, row in test_df.iterrows():
            question = row["Question"]
            question_type, _ = engine.data_processor.extract_choice_range(question)
            
            if question_type == "subjective":
                subjective_questions.append(idx)
            
            if len(subjective_questions) >= test_size:
                break
        
        if len(subjective_questions) == 0:
            print("ì£¼ê´€ì‹ ë¬¸í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒ ë¬¸í•­ë“¤ì„ ì£¼ê´€ì‹ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            subjective_questions = list(range(min(test_size, len(test_df))))
        
        print(f"ì£¼ê´€ì‹ ë¬¸í•­ {len(subjective_questions)}ê°œ ì„ ë³„ ì™„ë£Œ")

        # ì£¼ê´€ì‹ ë¬¸í•­ë§Œ í…ŒìŠ¤íŠ¸
        subjective_test_df = test_df.iloc[subjective_questions].copy()
        subjective_submission_df = submission_df.iloc[subjective_questions].copy()

        output_file = "./enhanced_subjective_test_result.csv"
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        results = engine.execute_inference_with_data(
            subjective_test_df, subjective_submission_df, output_file
        )
        end_time = time.time()

        # ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥
        print_enhanced_subjective_results(
            results, output_file, len(subjective_questions), 
            subjective_test_df["ID"].tolist(), end_time - start_time
        )

        # ì¶”ê°€ í’ˆì§ˆ ë¶„ì„
        analyze_subjective_quality(output_file, subjective_test_df, results)

        return True

    except Exception as e:
        print(f"ì£¼ê´€ì‹ íŠ¹í™” í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        if engine:
            engine.cleanup()


def run_template_effectiveness_test(test_size: int = 10):
    """í…œí”Œë¦¿ í™œìš© íš¨ê³¼ì„± í…ŒìŠ¤íŠ¸"""
    
    print(f"\n=== í…œí”Œë¦¿ í™œìš© íš¨ê³¼ì„± í…ŒìŠ¤íŠ¸ ===")
    print("í…œí”Œë¦¿ ê¸°ë°˜ ë‹µë³€ vs ì¼ë°˜ ë‹µë³€ ë¹„êµ í…ŒìŠ¤íŠ¸")

    engine = None
    try:
        # AI ì—”ì§„ ì´ˆê¸°í™”
        engine = FinancialAIInference(verbose=True)

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        import pandas as pd
        test_df = pd.read_csv(DEFAULT_FILES["test_file"])
        
        # ì£¼ê´€ì‹ ë¬¸í•­ ì„ ë³„
        subjective_indices = []
        for idx, row in test_df.iterrows():
            question = row["Question"]
            question_type, _ = engine.data_processor.extract_choice_range(question)
            if question_type == "subjective":
                subjective_indices.append(idx)
            if len(subjective_indices) >= test_size:
                break

        if not subjective_indices:
            subjective_indices = list(range(min(test_size, len(test_df))))

        print(f"í…œí”Œë¦¿ íš¨ê³¼ì„± í…ŒìŠ¤íŠ¸: {len(subjective_indices)}ê°œ ë¬¸í•­")

        template_results = []
        for idx in subjective_indices:
            row = test_df.iloc[idx]
            question = row["Question"]
            question_id = row["ID"]
            
            print(f"\ní…ŒìŠ¤íŠ¸ ë¬¸í•­: {question_id}")
            print(f"ì§ˆë¬¸: {question[:100]}...")
            
            # í…œí”Œë¦¿ ê¸°ë°˜ ë‹µë³€ ìƒì„±
            answer = engine.process_single_question(question, question_id)
            
            # ë‹µë³€ í’ˆì§ˆ ë¶„ì„
            korean_ratio = engine.data_processor.calculate_korean_ratio(answer)
            has_repetition = engine.model_handler.detect_critical_repetitive_patterns(answer)
            
            template_results.append({
                "question_id": question_id,
                "answer_length": len(answer),
                "korean_ratio": korean_ratio,
                "has_repetition": has_repetition,
                "answer_preview": answer[:150]
            })
            
            print(f"ë‹µë³€ ê¸¸ì´: {len(answer)}")
            print(f"í•œêµ­ì–´ ë¹„ìœ¨: {korean_ratio:.2%}")
            print(f"ë°˜ë³µ íŒ¨í„´: {'ìˆìŒ' if has_repetition else 'ì—†ìŒ'}")
            print(f"ë‹µë³€: {answer[:100]}...")

        # ê²°ê³¼ ìš”ì•½
        print(f"\n=== í…œí”Œë¦¿ íš¨ê³¼ì„± í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ===")
        avg_length = sum(r["answer_length"] for r in template_results) / len(template_results)
        avg_korean_ratio = sum(r["korean_ratio"] for r in template_results) / len(template_results)
        repetition_count = sum(1 for r in template_results if r["has_repetition"])
        
        print(f"í‰ê·  ë‹µë³€ ê¸¸ì´: {avg_length:.1f}ì")
        print(f"í‰ê·  í•œêµ­ì–´ ë¹„ìœ¨: {avg_korean_ratio:.1%}")
        print(f"ë°˜ë³µ íŒ¨í„´ ë°œìƒ: {repetition_count}/{len(template_results)}ê°œ")
        print(f"í’ˆì§ˆ ì„±ê³µë¥ : {((len(template_results) - repetition_count) / len(template_results)):.1%}")

        return True

    except Exception as e:
        print(f"í…œí”Œë¦¿ íš¨ê³¼ì„± í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        return False
    finally:
        if engine:
            engine.cleanup()


def run_intent_analysis_accuracy_test(test_size: int = 15):
    """ì˜ë„ ë¶„ì„ ì •í™•ë„ í…ŒìŠ¤íŠ¸"""
    
    print(f"\n=== ì˜ë„ ë¶„ì„ ì •í™•ë„ í…ŒìŠ¤íŠ¸ ===")
    print("ì§ˆë¬¸ ì˜ë„ ë¶„ì„ê³¼ ë‹µë³€ ì¼ì¹˜ì„± ê²€ì¦")

    engine = None
    try:
        # AI ì—”ì§„ ì´ˆê¸°í™”
        engine = FinancialAIInference(verbose=True)

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        import pandas as pd
        test_df = pd.read_csv(DEFAULT_FILES["test_file"])
        
        # ë‹¤ì–‘í•œ ì˜ë„ì˜ ë¬¸í•­ ì„ ë³„
        intent_results = {}
        processed_count = 0
        
        for idx, row in test_df.iterrows():
            if processed_count >= test_size:
                break
                
            question = row["Question"]
            question_id = row["ID"]
            question_type, _ = engine.data_processor.extract_choice_range(question)
            
            if question_type == "subjective":
                # ì˜ë„ ë¶„ì„
                intent_analysis = engine.data_processor.analyze_question_intent(question)
                primary_intent = intent_analysis.get("primary_intent", "ì¼ë°˜")
                confidence = intent_analysis.get("intent_confidence", 0)
                
                if primary_intent not in intent_results:
                    intent_results[primary_intent] = []
                
                # ë‹µë³€ ìƒì„±
                answer = engine.process_single_question(question, question_id)
                
                # ì˜ë„-ë‹µë³€ ì¼ì¹˜ì„± ê²€ì¦
                intent_match = engine.data_processor.validate_answer_intent_match(
                    answer, question, intent_analysis
                )
                
                intent_results[primary_intent].append({
                    "question_id": question_id,
                    "confidence": confidence,
                    "intent_match": intent_match,
                    "answer_length": len(answer)
                })
                
                print(f"ë¬¸í•­ {question_id}: {primary_intent} (ì‹ ë¢°ë„: {confidence:.2f}, ì¼ì¹˜: {intent_match})")
                processed_count += 1

        # ê²°ê³¼ ë¶„ì„
        print(f"\n=== ì˜ë„ ë¶„ì„ ì •í™•ë„ ê²°ê³¼ ===")
        total_matches = 0
        total_questions = 0
        
        for intent, results in intent_results.items():
            match_count = sum(1 for r in results if r["intent_match"])
            avg_confidence = sum(r["confidence"] for r in results) / len(results)
            
            print(f"{intent}: {match_count}/{len(results)} ì¼ì¹˜ "
                  f"(ì„±ê³µë¥ : {match_count/len(results):.1%}, í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f})")
            
            total_matches += match_count
            total_questions += len(results)
        
        overall_accuracy = total_matches / total_questions if total_questions > 0 else 0
        print(f"\nì „ì²´ ì˜ë„-ë‹µë³€ ì¼ì¹˜ ì •í™•ë„: {overall_accuracy:.1%}")

        return True

    except Exception as e:
        print(f"ì˜ë„ ë¶„ì„ ì •í™•ë„ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        return False
    finally:
        if engine:
            engine.cleanup()


def run_test(test_size: int = None, verbose: bool = True, relax_standards: bool = False):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ì¼ë°˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""

    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ í¬ê¸° ì„¤ì •
    if test_size is None:
        test_size = 50

    # í’ˆì§ˆ ê¸°ì¤€ ì™„í™” ì˜µì…˜
    if relax_standards:
        print("í’ˆì§ˆ ê¸°ì¤€ì„ ì™„í™”í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        relax_quality_standards()

    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    test_file = DEFAULT_FILES["test_file"]
    submission_file = DEFAULT_FILES["submission_file"]

    for file_path in [test_file, submission_file]:
        if not os.path.exists(file_path):
            print(f"ì˜¤ë¥˜: {file_path} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return False

    engine = None
    try:
        # ì„¤ì • ìš”ì•½ ì¶œë ¥
        if verbose:
            print_config_summary()

        # AI ì—”ì§„ ì´ˆê¸°í™”
        print("\nì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        engine = FinancialAIInference(verbose=verbose)

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        import pandas as pd

        test_df = pd.read_csv(test_file, encoding=FILE_VALIDATION["encoding"])
        submission_df = pd.read_csv(
            submission_file, encoding=FILE_VALIDATION["encoding"]
        )

        print(f"ì „ì²´ ë°ì´í„°: {len(test_df)}ê°œ ë¬¸í•­")
        print(f"í…ŒìŠ¤íŠ¸ í¬ê¸°: {test_size}ê°œ ë¬¸í•­")

        # ì§€ì •ëœ í¬ê¸°ë¡œ ì œí•œ
        if len(test_df) > test_size:
            test_df = test_df.head(test_size)
            temp_submission = submission_df.head(test_size).copy()

            output_file = DEFAULT_FILES["test_output_file"]
            results = engine.execute_inference_with_data(
                test_df, temp_submission, output_file
            )
        else:
            output_file = DEFAULT_FILES["test_output_file"]
            results = engine.execute_inference(test_file, submission_file, output_file)

        # ê²°ê³¼ ë¶„ì„
        print_enhanced_results(results, output_file, test_size, verbose)

        return True

    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        if engine:
            engine.cleanup()


def print_enhanced_subjective_results(
    results: dict, output_file: str, test_count: int, question_ids: list, execution_time: float
):
    """ì£¼ê´€ì‹ íŠ¹í™” í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶œë ¥"""
    
    print(f"\n=== ì£¼ê´€ì‹ ë‹µë³€ ìƒì„± íŠ¹í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
    print(f"ì²˜ë¦¬ ë¬¸í•­: {test_count}ê°œ")
    print(f"ì²˜ë¦¬ ì‹œê°„: {execution_time:.1f}ì´ˆ")
    print(f"í‰ê·  ë¬¸í•­ë‹¹ ì‹œê°„: {execution_time/test_count:.1f}ì´ˆ")
    print(f"ê²°ê³¼ íŒŒì¼: {output_file}")
    
    # ì²˜ë¦¬ëœ ë¬¸í•­ ID ì¶œë ¥
    print(f"\n=== ì²˜ë¦¬ëœ ë¬¸í•­ ID ===")
    print(f"ì´ {len(question_ids)}ê°œ ë¬¸í•­: {', '.join(question_ids[:10])}{'...' if len(question_ids) > 10 else ''}")
    
    # ì£¼ê´€ì‹ íŠ¹í™” í†µê³„
    if "debug_counters" in results:
        debug_info = results["debug_counters"]
        enhancement_info = results.get("enhancement_applied", {})
        
        print(f"\n=== ì£¼ê´€ì‹ ë‹µë³€ ìƒì„± íŠ¹í™” í†µê³„ ===")
        print(f"ì´ ì£¼ê´€ì‹ ë¬¸í•­: {debug_info.get('subjective_questions', 0)}")
        print(f"í…œí”Œë¦¿ ìœµí•© í™œìš©: {enhancement_info.get('template_fusion', 0)}")
        print(f"ìì—°ìŠ¤ëŸ¬ìš´ ìƒì„±: {enhancement_info.get('natural_generation', 0)}")
        print(f"í’ˆì§ˆ í–¥ìƒ ì ìš©: {enhancement_info.get('quality_enhancement', 0)}")
        print(f"í•œêµ­ì–´ ìµœì í™”: {enhancement_info.get('korean_optimization', 0)}")
        print(f"í´ë°± ì‚¬ìš©: {debug_info.get('fallback_used', 0)}")
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        subjective_count = debug_info.get('subjective_questions', test_count)
        if subjective_count > 0:
            template_fusion_rate = enhancement_info.get('template_fusion', 0) / subjective_count
            quality_enhancement_rate = enhancement_info.get('quality_enhancement', 0) / subjective_count
            korean_optimization_rate = enhancement_info.get('korean_optimization', 0) / subjective_count
            
            print(f"\n=== ì„±ëŠ¥ ì§€í‘œ ===")
            print(f"í…œí”Œë¦¿ ìœµí•© í™œìš©ë¥ : {template_fusion_rate:.1%}")
            print(f"í’ˆì§ˆ í–¥ìƒ ì ìš©ë¥ : {quality_enhancement_rate:.1%}")
            print(f"í•œêµ­ì–´ ìµœì í™”ìœ¨: {korean_optimization_rate:.1%}")
            
            # ì„±ëŠ¥ í‰ê°€
            if template_fusion_rate >= 0.8:
                print("âœ… í…œí”Œë¦¿ í™œìš©ì´ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤")
            elif template_fusion_rate >= 0.6:
                print("âœ… í…œí”Œë¦¿ í™œìš©ì´ ì–‘í˜¸í•©ë‹ˆë‹¤")
            else:
                print("âš ï¸  í…œí”Œë¦¿ í™œìš©ë¥ ì„ ê°œì„ í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤")
            
            if quality_enhancement_rate >= 0.9:
                print("âœ… í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œì´ ìš°ìˆ˜í•©ë‹ˆë‹¤")
            elif quality_enhancement_rate >= 0.7:
                print("âœ… í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œì´ ì–‘í˜¸í•©ë‹ˆë‹¤")
            else:
                print("âš ï¸  í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œì„ ê°œì„ í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤")

    print("="*60)


def analyze_subjective_quality(output_file: str, test_df, results: dict):
    """ì£¼ê´€ì‹ ë‹µë³€ í’ˆì§ˆ ë¶„ì„"""
    
    print(f"\n=== ì£¼ê´€ì‹ ë‹µë³€ í’ˆì§ˆ ë¶„ì„ ===")
    
    try:
        import pandas as pd
        result_df = pd.read_csv(output_file)
        
        quality_metrics = {
            "total_answers": len(result_df),
            "empty_answers": 0,
            "short_answers": 0,  # 30ì ë¯¸ë§Œ
            "optimal_answers": 0,  # 30-300ì
            "long_answers": 0,  # 300ì ì´ˆê³¼
            "korean_dominant": 0,  # í•œêµ­ì–´ ë¹„ìœ¨ 80% ì´ìƒ
            "natural_sentences": 0,  # ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ êµ¬ì¡°
        }
        
        for idx, row in result_df.iterrows():
            answer = str(row.get("Answer", ""))
            
            if not answer or answer.strip() == "":
                quality_metrics["empty_answers"] += 1
                continue
            
            length = len(answer)
            if length < 30:
                quality_metrics["short_answers"] += 1
            elif length <= 300:
                quality_metrics["optimal_answers"] += 1
            else:
                quality_metrics["long_answers"] += 1
            
            # í•œêµ­ì–´ ë¹„ìœ¨ ê³„ì‚°
            korean_chars = len([c for c in answer if '\uAC00' <= c <= '\uD7A3'])
            total_chars = len([c for c in answer if c.isalpha()])
            korean_ratio = korean_chars / total_chars if total_chars > 0 else 0
            
            if korean_ratio >= 0.8:
                quality_metrics["korean_dominant"] += 1
            
            # ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ êµ¬ì¡° í™•ì¸
            if (answer.endswith((".", "ë‹¤", "ìš”", "í•¨", "ë‹ˆë‹¤", "ìŠµë‹ˆë‹¤")) and 
                "." in answer and 
                not any(problem in answer for problem in ["ê°ˆì·¨", "ë¬»ê³ "])):
                quality_metrics["natural_sentences"] += 1
        
        # í’ˆì§ˆ ì§€í‘œ ì¶œë ¥
        total = quality_metrics["total_answers"]
        print(f"ì´ ë‹µë³€ ìˆ˜: {total}")
        print(f"ë¹ˆ ë‹µë³€: {quality_metrics['empty_answers']} ({quality_metrics['empty_answers']/total:.1%})")
        print(f"ì§§ì€ ë‹µë³€ (30ì ë¯¸ë§Œ): {quality_metrics['short_answers']} ({quality_metrics['short_answers']/total:.1%})")
        print(f"ì ì • ë‹µë³€ (30-300ì): {quality_metrics['optimal_answers']} ({quality_metrics['optimal_answers']/total:.1%})")
        print(f"ê¸´ ë‹µë³€ (300ì ì´ˆê³¼): {quality_metrics['long_answers']} ({quality_metrics['long_answers']/total:.1%})")
        print(f"í•œêµ­ì–´ ìš°ìˆ˜ (80% ì´ìƒ): {quality_metrics['korean_dominant']} ({quality_metrics['korean_dominant']/total:.1%})")
        print(f"ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥: {quality_metrics['natural_sentences']} ({quality_metrics['natural_sentences']/total:.1%})")
        
        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_score = (
            quality_metrics['optimal_answers'] * 3 +
            quality_metrics['korean_dominant'] * 2 + 
            quality_metrics['natural_sentences'] * 2 +
            quality_metrics['long_answers'] * 1 -
            quality_metrics['short_answers'] * 1 -
            quality_metrics['empty_answers'] * 3
        ) / (total * 8) * 100
        
        print(f"\nì „ì²´ í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}/100")
        
        if quality_score >= 80:
            print("ğŸŒŸ ìš°ìˆ˜í•œ ë‹µë³€ í’ˆì§ˆì…ë‹ˆë‹¤!")
        elif quality_score >= 60:
            print("âœ… ì–‘í˜¸í•œ ë‹µë³€ í’ˆì§ˆì…ë‹ˆë‹¤.")
        elif quality_score >= 40:
            print("âš ï¸  ë‹µë³€ í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            print("âŒ ë‹µë³€ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"í’ˆì§ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")


def print_enhanced_results(results: dict, output_file: str, test_count: int, verbose: bool = True):
    """í–¥ìƒëœ ê²°ê³¼ ì¶œë ¥ (ê¸°ì¡´ í˜¸í™˜ì„±)"""
    
    total_time_minutes = results["total_time"] / 60
    print(f"\n=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ({test_count}ê°œ ë¬¸í•­) ===")
    print(f"ì²˜ë¦¬ ì‹œê°„: {total_time_minutes:.2f}ë¶„")
    print(f"í‰ê·  ë¬¸í•­ë‹¹ ì‹œê°„: {results['total_time']/test_count:.2f}ì´ˆ")
    print(f"ê²°ê³¼ íŒŒì¼: {output_file}")
    
    # ë””ë²„ê¹… í†µê³„ ì¶œë ¥
    if "debug_counters" in results and verbose:
        debug_info = results["debug_counters"]
        print(f"\n=== ìƒì„¸ ì²˜ë¦¬ í†µê³„ ===")
        print(f"ì´ ì§ˆë¬¸ ìˆ˜: {debug_info.get('total_questions', 0)}")
        print(f"ì£¼ê´€ì‹ ì§ˆë¬¸: {debug_info.get('subjective_questions', 0)}")
        print(f"í…œí”Œë¦¿ í™œìš©: {debug_info.get('template_used', 0)}")
        print(f"í´ë°± ì‚¬ìš©: {debug_info.get('fallback_used', 0)}")
        print(f"í’ˆì§ˆ ê²€ì¦ í†µê³¼: {debug_info.get('quality_passed', 0)}")
        
        # í–¥ìƒëœ í†µê³„ ì¶œë ¥
        if "enhancement_applied" in results:
            enhancement_info = results["enhancement_applied"]
            print(f"\n=== ë‹µë³€ ìƒì„± ê°•í™” í†µê³„ ===")
            print(f"í…œí”Œë¦¿ ìœµí•©: {enhancement_info.get('template_fusion', 0)}")
            print(f"ìì—°ìŠ¤ëŸ¬ìš´ ìƒì„±: {enhancement_info.get('natural_generation', 0)}")
            print(f"í’ˆì§ˆ í–¥ìƒ: {enhancement_info.get('quality_enhancement', 0)}")
            print(f"í•œêµ­ì–´ ìµœì í™”: {enhancement_info.get('korean_optimization', 0)}")
    
    print("="*60)


def select_test_type():
    """í…ŒìŠ¤íŠ¸ ìœ í˜• ì„ íƒ"""
    print("\n=== AI ê¸ˆìœµë³´ì•ˆ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ (ì£¼ê´€ì‹ íŠ¹í™” ë²„ì „) ===")
    print("ì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print()
    print("1. ì£¼ê´€ì‹ ë‹µë³€ ìƒì„± íŠ¹í™” í…ŒìŠ¤íŠ¸ (ì¶”ì²œ)")
    print("2. í…œí”Œë¦¿ í™œìš© íš¨ê³¼ì„± í…ŒìŠ¤íŠ¸")
    print("3. ì˜ë„ ë¶„ì„ ì •í™•ë„ í…ŒìŠ¤íŠ¸")
    print("4. ê¸°ë³¸ í†µí•© í…ŒìŠ¤íŠ¸")
    print()

    while True:
        try:
            choice = input("ì„ íƒ (1-4): ").strip()

            if choice == "1":
                return "subjective_enhanced"
            elif choice == "2":
                return "template_effectiveness"
            elif choice == "3":
                return "intent_accuracy"
            elif choice == "4":
                return "basic_test"
            else:
                print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1, 2, 3, 4 ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

        except KeyboardInterrupt:
            print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            sys.exit(0)
        except Exception:
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")


def select_test_size(test_type: str):
    """í…ŒìŠ¤íŠ¸ í¬ê¸° ì„ íƒ"""
    print(f"\n{test_type} í…ŒìŠ¤íŠ¸ í¬ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    
    if test_type == "ì£¼ê´€ì‹ íŠ¹í™”":
        options = {
            "1": 5,
            "2": 10,
            "3": 20,
            "4": 30,
            "5": 50
        }
        print("1. 5ë¬¸í•­ (ë¹ ë¥¸ í™•ì¸)")
        print("2. 10ë¬¸í•­ (ê¸°ë³¸ í…ŒìŠ¤íŠ¸)")
        print("3. 20ë¬¸í•­ (ìƒì„¸ í…ŒìŠ¤íŠ¸)")
        print("4. 30ë¬¸í•­ (ì¢…í•© í…ŒìŠ¤íŠ¸)")
        print("5. 50ë¬¸í•­ (ì „ì²´ í‰ê°€)")
    else:
        options = {
            "1": 5,
            "2": 10,
            "3": 15,
            "4": 25,
            "5": 50
        }
        print("1. 5ë¬¸í•­ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)")
        print("2. 10ë¬¸í•­ (ê¸°ë³¸ í…ŒìŠ¤íŠ¸)")
        print("3. 15ë¬¸í•­ (ìƒì„¸ í…ŒìŠ¤íŠ¸)")
        print("4. 25ë¬¸í•­ (ì¢…í•© í…ŒìŠ¤íŠ¸)")
        print("5. 50ë¬¸í•­ (ì „ì²´ í…ŒìŠ¤íŠ¸)")
    
    print()

    while True:
        try:
            choice = input("ì„ íƒ (1-5): ").strip()

            if choice in options:
                return options[choice]
            else:
                print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1, 2, 3, 4, 5 ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

        except KeyboardInterrupt:
            print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            sys.exit(0)
        except Exception:
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    # í…ŒìŠ¤íŠ¸ ìœ í˜• ì„ íƒ
    test_type = select_test_type()
    
    if test_type == "subjective_enhanced":
        test_size = select_test_size("ì£¼ê´€ì‹ íŠ¹í™”")
        print(f"\nì£¼ê´€ì‹ ë‹µë³€ ìƒì„± íŠ¹í™” í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤... ({test_size}ë¬¸í•­)")
        success = run_enhanced_subjective_test(test_size, verbose=True)
        
    elif test_type == "template_effectiveness":
        test_size = select_test_size("í…œí”Œë¦¿ íš¨ê³¼ì„±")
        print(f"\ní…œí”Œë¦¿ í™œìš© íš¨ê³¼ì„± í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤... ({test_size}ë¬¸í•­)")
        success = run_template_effectiveness_test(test_size)
        
    elif test_type == "intent_accuracy":
        test_size = select_test_size("ì˜ë„ ë¶„ì„")
        print(f"\nì˜ë„ ë¶„ì„ ì •í™•ë„ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤... ({test_size}ë¬¸í•­)")
        success = run_intent_analysis_accuracy_test(test_size)
        
    else:  # basic_test
        test_size = select_test_size("ê¸°ë³¸ í†µí•©")
        print(f"\nê¸°ë³¸ í†µí•© í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤... ({test_size}ë¬¸í•­)")
        success = run_test(test_size, verbose=True)
    
    if success:
        print(f"\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    else:
        print(f"\ní…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        sys.exit(1)


if __name__ == "__main__":
    main()