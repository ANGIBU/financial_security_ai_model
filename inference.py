# inference.py

import re
import time
import gc
import pickle
import pandas as pd
import sys
from typing import Dict
from pathlib import Path
from tqdm import tqdm
from datetime import datetime

from config import (
    setup_environment,
    DEFAULT_MODEL_NAME,
    OPTIMIZATION_CONFIG,
    MEMORY_CONFIG,
    TIME_LIMITS,
    DEFAULT_FILES,
    FILE_VALIDATION,
    PKL_FILES,
    ensure_directories,
    get_device,
)

current_dir = Path(__file__).parent.absolute()

from model_handler import ModelHandler
from data_processor import DataProcessor
from knowledge_base import KnowledgeBase
from prompt_enhancer import PromptEnhancer


class LearningSystem:
    def __init__(self):
        try:
            ensure_directories()
            self.successful_answers = self.load_pkl_data("successful_answers")
            self.failed_answers = self.load_pkl_data("failed_answers")
            self.question_patterns = self.load_pkl_data("question_patterns")
            self.domain_templates = self.load_pkl_data("domain_templates")
            self.mc_patterns = self.load_pkl_data("mc_patterns")
            self.performance_data = self.load_pkl_data("performance_data")
            self.answer_diversity_tracker = {}
            self.domain_accuracy = {}
        except Exception as e:
            print(f"í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._initialize_empty_data()
    
    def _initialize_empty_data(self):
        self.successful_answers = {}
        self.failed_answers = {}
        self.question_patterns = {}
        self.domain_templates = {}
        self.mc_patterns = {}
        self.performance_data = {}
        self.answer_diversity_tracker = {}
        self.domain_accuracy = {}
    
    def load_pkl_data(self, data_type: str) -> Dict:
        try:
            file_path = PKL_FILES.get(data_type)
            if not file_path:
                return {}
                
            if file_path.exists():
                with open(file_path, 'rb') as f:
                    data = pickle.load(f)
                    return data if isinstance(data, dict) else {}
            return {}
        except Exception as e:
            print(f"pkl ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ({data_type}): {e}")
            return {}
    
    def save_pkl_data(self, data_type: str, data: Dict):
        try:
            file_path = PKL_FILES.get(data_type)
            if not file_path or not isinstance(data, dict):
                return False
                
            with open(file_path, 'wb') as f:
                pickle.dump(data, f)
            return True
        except Exception as e:
            print(f"pkl ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ ({data_type}): {e}")
            return False
    
    def is_answer_duplicate(self, answer: str, question_id: str, domain: str, threshold: float = 0.8) -> bool:
        try:
            if not answer or len(answer) < 15:
                return False
            
            answer_normalized = re.sub(r'[^\wê°€-í£]', '', answer.lower())
            
            for qid, data in self.successful_answers.items():
                if qid == question_id or data.get("domain") != domain:
                    continue
                    
                existing_answer = data.get("answer", "")
                existing_normalized = re.sub(r'[^\wê°€-í£]', '', existing_answer.lower())
                
                if len(existing_normalized) == 0:
                    continue
                    
                similarity = len(set(answer_normalized) & set(existing_normalized)) / len(set(answer_normalized) | set(existing_normalized))
                
                if similarity > threshold:
                    return True
            
            return False
        except Exception as e:
            print(f"ì¤‘ë³µ í™•ì¸ ì˜¤ë¥˜: {e}")
            return False
    
    def record_successful_answer(self, question_id: str, question: str, answer: str, 
                                question_type: str, domain: str, method: str):
        try:
            if not all([question_id, question, answer, question_type, domain, method]):
                return False
            
            if self.is_answer_duplicate(answer, question_id, domain, threshold=0.9):
                return False
                
            self.successful_answers[question_id] = {
                "question": question,
                "answer": answer,
                "question_type": question_type,
                "domain": domain,
                "method": method,
                "timestamp": datetime.now().isoformat(),
                "answer_length": len(str(answer)),
                "question_hash": hash(question[:100]),
                "quality_score": self._calculate_answer_quality(answer)
            }
            
            if domain not in self.domain_accuracy:
                self.domain_accuracy[domain] = {"success": 0, "total": 0}
            self.domain_accuracy[domain]["success"] += 1
            self.domain_accuracy[domain]["total"] += 1
            
            max_count = MEMORY_CONFIG["max_learning_records"]["successful_answers"]
            if len(self.successful_answers) > max_count:
                self._cleanup_old_records("successful_answers")
                
            return True
        except Exception as e:
            print(f"ì„±ê³µ ë‹µë³€ ê¸°ë¡ ì‹¤íŒ¨: {e}")
            return False
    
    def _calculate_answer_quality(self, answer: str) -> float:
        try:
            score = 0.0
            
            length = len(answer)
            if 25 <= length <= 600:  # ë” ì—„ê²©í•œ ê¸¸ì´ ê¸°ì¤€
                score += 0.4
            elif length > 15:
                score += 0.2
            
            korean_chars = len(re.findall(r'[ê°€-í£]', answer))
            total_chars = len(re.sub(r'[^\wê°€-í£]', '', answer))
            if total_chars > 0:
                korean_ratio = korean_chars / total_chars
                if korean_ratio >= 0.8:  # ë†’ì€ í•œêµ­ì–´ ë¹„ìœ¨
                    score += 0.3
                elif korean_ratio >= 0.6:
                    score += 0.2
            
            professional_terms = ['ë²•', 'ê·œì •', 'ê´€ë¦¬', 'ì²´ê³„', 'ì¡°ì¹˜', 'ë³´ì•ˆ', 'ë°©ì•ˆ', 'ì ˆì°¨', 
                                 'ê¸°ê´€', 'ìœ„ì›íšŒ', 'ì—…ë¬´', 'ë‹´ë‹¹', 'ê¶Œí•œ', 'ì˜ë¬´', 'ì›ì¹™']
            term_count = sum(1 for term in professional_terms if term in answer)
            score += min(term_count * 0.05, 0.3)
            
            return min(score, 1.0)
        except Exception:
            return 0.5
    
    def _cleanup_old_records(self, record_type: str):
        try:
            records = getattr(self, record_type)
            if not records:
                return
                
            sorted_items = sorted(
                records.items(),
                key=lambda x: (
                    x[1].get("quality_score", 0.0),
                    x[1].get("timestamp", "")
                )
            )
            
            remove_count = len(sorted_items) // 4
            for key, _ in sorted_items[:remove_count]:
                del records[key]
                
        except Exception as e:
            print(f"ê¸°ë¡ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_similar_successful_answer(self, question: str, domain: str, question_type: str) -> str:
        try:
            if not question or not domain:
                return None
                
            question_lower = question.lower()
            best_match = None
            best_score = 0
            
            for qid, data in self.successful_answers.items():
                if data.get("domain") != domain or data.get("question_type") != question_type:
                    continue
                    
                stored_question = data.get("question", "").lower()
                if not stored_question:
                    continue
                
                question_keywords = set(re.findall(r'[ê°€-í£]{2,}', question_lower))
                stored_keywords = set(re.findall(r'[ê°€-í£]{2,}', stored_question))
                
                if not question_keywords:
                    continue
                
                intersection = question_keywords & stored_keywords
                union = question_keywords | stored_keywords
                
                if len(union) == 0:
                    continue
                    
                similarity = len(intersection) / len(union)
                quality_bonus = data.get("quality_score", 0.5) * 0.2
                final_score = similarity + quality_bonus
                
                if final_score > best_score and similarity > 0.4:  # ë” ë†’ì€ ìœ ì‚¬ë„ ê¸°ì¤€
                    best_score = final_score
                    best_match = data.get("answer")
            
            return best_match if best_match and len(str(best_match).strip()) > 20 else None
        except Exception as e:
            print(f"ìœ ì‚¬ ë‹µë³€ ì°¾ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def record_failed_answer(self, question_id: str, question: str, error: str,
                           question_type: str, domain: str):
        try:
            self.failed_answers[question_id] = {
                "question": question,
                "error": error,
                "question_type": question_type,
                "domain": domain,
                "timestamp": datetime.now().isoformat()
            }
            
            if domain not in self.domain_accuracy:
                self.domain_accuracy[domain] = {"success": 0, "total": 0}
            self.domain_accuracy[domain]["total"] += 1
            
        except Exception as e:
            print(f"ì‹¤íŒ¨ ë‹µë³€ ê¸°ë¡ ì‹¤íŒ¨: {e}")
    
    def save_all_data(self):
        try:
            save_results = {
                "successful_answers": self.save_pkl_data("successful_answers", self.successful_answers),
                "failed_answers": self.save_pkl_data("failed_answers", self.failed_answers),
                "question_patterns": self.save_pkl_data("question_patterns", self.question_patterns),
                "domain_templates": self.save_pkl_data("domain_templates", self.domain_templates),
                "mc_patterns": self.save_pkl_data("mc_patterns", self.mc_patterns),
                "performance_data": self.save_pkl_data("performance_data", self.performance_data)
            }
            
            failed_saves = [k for k, v in save_results.items() if not v]
            return len(failed_saves) == 0
        except Exception as e:
            print(f"ì „ì²´ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False


class FinancialAIInference:
    def __init__(self, verbose: bool = False):
        self.verbose = verbose
        self.start_time = time.time()

        try:
            setup_environment()
            ensure_directories()
        except Exception as e:
            print(f"í™˜ê²½ ì„¤ì • ì‹¤íŒ¨: {e}")
            sys.exit(1)

        try:
            self.learning = LearningSystem()
            self.model_handler = ModelHandler(verbose=False)
            self.data_processor = DataProcessor()
            self.knowledge_base = KnowledgeBase()
            self.prompt_enhancer = PromptEnhancer()

            # ì •í™•ë„ ìµœì í™”ë¥¼ ìœ„í•œ ì„¤ì •
            self.optimization_config = OPTIMIZATION_CONFIG.copy()
            self.optimization_config.update({
                "temperature": 0.3,  # ë” ë‚®ì€ temperature
                "top_p": 0.8,
                "diversity_threshold": 0.8,
                "quality_threshold": 0.9,
                "korean_ratio_threshold": 0.8,
                "max_retry_attempts": 3
            })
            
            self.total_questions = 0
            self.successful_processing = 0
            self.failed_processing = 0
            self.domain_performance = {}
            
            # ì •í™•ë„ ì¶”ì 
            self.accuracy_tracking = {
                "mc_correct": 0,
                "mc_total": 0,
                "subjective_valid": 0,
                "subjective_total": 0
            }
            
        except Exception as e:
            print(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            sys.exit(1)

    def process_single_question(self, question: str, question_id: str) -> str:
        """ë‹¨ì¼ ì§ˆë¬¸ ì²˜ë¦¬ - ì •í™•ë„ ìµœì í™”"""
        start_time = time.time()
        
        try:
            if not question or not question_id:
                return self._get_enhanced_fallback_answer("subjective", question, 5, "ì¼ë°˜")
            
            # 1ë‹¨ê³„: ì§ˆë¬¸ ë¶„ì„ (ì •í™•ë„ í–¥ìƒ)
            question_type, max_choice = self.data_processor.extract_choice_range(question)
            domain = self.data_processor.extract_domain(question)
            difficulty = self.data_processor.analyze_question_difficulty(question)
            
            if self.verbose:
                print(f"ì§ˆë¬¸ ë¶„ì„ - íƒ€ì…: {question_type}, ë„ë©”ì¸: {domain}, ë‚œì´ë„: {difficulty}")
            
            # 2ë‹¨ê³„: í•™ìŠµëœ ìœ ì‚¬ ë‹µë³€ í™•ì¸ (ë” ì—„ê²©í•œ ê¸°ì¤€)
            if self.optimization_config.get("pkl_learning_enabled", True):
                similar_answer = self.learning.get_similar_successful_answer(question, domain, question_type)
                if similar_answer and len(str(similar_answer).strip()) > 20:
                    if not self.learning.is_answer_duplicate(similar_answer, question_id, domain, threshold=0.85):
                        self.learning.record_successful_answer(question_id, question, similar_answer, 
                                                             question_type, domain, "learning_match")
                        self.successful_processing += 1
                        self._update_domain_performance(domain, True)
                        self._update_accuracy_tracking(question_type, True)
                        return similar_answer

            # 3ë‹¨ê³„: ì§€ì‹ë² ì´ìŠ¤ ë¶„ì„
            try:
                kb_analysis = self.knowledge_base.analyze_question(question)
            except Exception as e:
                print(f"ì§€ì‹ë² ì´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {e}")
                kb_analysis = {}

            # 4ë‹¨ê³„: ì˜ë„ ë¶„ì„ (ì£¼ê´€ì‹ë§Œ)
            intent_analysis = None
            if question_type == "subjective":
                try:
                    intent_analysis = self.data_processor.analyze_question_intent(question)
                except Exception as e:
                    print(f"ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
                    intent_analysis = None

            # 5ë‹¨ê³„: ë‹¤ë‹¨ê³„ ë‹µë³€ ìƒì„± ì‹œë„
            answer = self._generate_answer_with_multi_stage_approach(
                question, question_type, max_choice, domain, intent_analysis, kb_analysis, question_id
            )

            # 6ë‹¨ê³„: ë‹µë³€ ê²€ì¦ ë° í›„ì²˜ë¦¬
            if answer and len(str(answer).strip()) > 0:
                validated_answer = self._validate_and_enhance_answer(answer, question, question_type, max_choice, domain, question_id)
                
                if validated_answer:
                    if not self.learning.is_answer_duplicate(validated_answer, question_id, domain, threshold=0.80):
                        self.learning.record_successful_answer(question_id, question, validated_answer, 
                                                             question_type, domain, "multi_stage_generation")
                    self.successful_processing += 1
                    self._update_domain_performance(domain, True)
                    self._update_accuracy_tracking(question_type, True)
                    return validated_answer

            # 7ë‹¨ê³„: ì‹¤íŒ¨ ì²˜ë¦¬
            self.learning.record_failed_answer(question_id, question, "ë‹µë³€ ìƒì„± ë° ê²€ì¦ ì‹¤íŒ¨", 
                                             question_type, domain)
            self.failed_processing += 1
            self._update_domain_performance(domain, False)
            self._update_accuracy_tracking(question_type, False)
            
            # ìµœì¢… í´ë°± ë‹µë³€
            return self._get_enhanced_fallback_answer(question_type, question, max_choice, domain)

        except Exception as e:
            return self._handle_processing_error(e, question_id, question, locals())

    def _generate_answer_with_multi_stage_approach(self, question: str, question_type: str, max_choice: int, 
                                                  domain: str, intent_analysis: Dict, kb_analysis: Dict, question_id: str) -> str:
        """ë‹¤ë‹¨ê³„ ì ‘ê·¼ ë°©ì‹ ë‹µë³€ ìƒì„±"""
        try:
            # 1ë‹¨ê³„: ê²€ì¦ëœ íŒ¨í„´ ë§¤ì¹­ (ê°ê´€ì‹)
            if question_type == "multiple_choice":
                verified_mc_answer = self._get_verified_mc_pattern_answer(question, max_choice, domain)
                if verified_mc_answer and verified_mc_answer != "2":  # ê¸°ë³¸ê°’ì´ ì•„ë‹Œ ê²½ìš°
                    return verified_mc_answer

            # 2ë‹¨ê³„: ê²€ì¦ëœ ë„ë©”ì¸ í…œí”Œë¦¿ (ì£¼ê´€ì‹)
            if question_type == "subjective":
                verified_template_answer = self._get_verified_template_answer(question, domain)
                if verified_template_answer:
                    return verified_template_answer

            # 3ë‹¨ê³„: í–¥ìƒëœ LLM ìƒì„±
            domain_hints = {
                "domain": domain,
                "temperature": self.optimization_config.get("temperature", 0.3),
                "top_p": self.optimization_config.get("top_p", 0.8),
                "difficulty": self.data_processor.analyze_question_difficulty(question),
                "context_boost": True,
                "accuracy_mode": True  # ì •í™•ë„ ìš°ì„  ëª¨ë“œ
            }

            answer = self.model_handler.generate_answer(
                question=question,
                question_type=question_type,
                max_choice=max_choice,
                intent_analysis=intent_analysis,
                domain_hints=domain_hints,
                knowledge_base=self.knowledge_base,
                prompt_enhancer=self.prompt_enhancer
            )

            return answer

        except Exception as e:
            print(f"ë‹¤ë‹¨ê³„ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            return None

    def _get_verified_mc_pattern_answer(self, question: str, max_choice: int, domain: str) -> str:
        """ê²€ì¦ëœ ê°ê´€ì‹ íŒ¨í„´ ë‹µë³€"""
        try:
            # model_handlerì˜ ê²€ì¦ëœ íŒ¨í„´ì„ í™œìš©
            return self.model_handler.get_verified_mc_answer(question, max_choice, domain)
        except Exception as e:
            print(f"ê²€ì¦ëœ MC íŒ¨í„´ ë‹µë³€ ì˜¤ë¥˜: {e}")
            return None

    def _get_verified_template_answer(self, question: str, domain: str) -> str:
        """ê²€ì¦ëœ í…œí”Œë¦¿ ë‹µë³€"""
        try:
            # model_handlerì˜ ê²€ì¦ëœ í…œí”Œë¦¿ì„ í™œìš©
            return self.model_handler.get_verified_domain_template_answer(question, domain)
        except Exception as e:
            print(f"ê²€ì¦ëœ í…œí”Œë¦¿ ë‹µë³€ ì˜¤ë¥˜: {e}")
            return None

    def _validate_and_enhance_answer(self, answer: str, question: str, question_type: str, 
                                   max_choice: int, domain: str, question_id: str) -> str:
        """ë‹µë³€ ê²€ì¦ ë° í–¥ìƒ"""
        try:
            if not answer:
                return None

            if question_type == "multiple_choice":
                return self._validate_enhanced_mc_answer(answer, question, max_choice, domain)
            else:
                return self._validate_enhanced_subjective_answer(answer, question, domain, question_id)

        except Exception as e:
            print(f"ë‹µë³€ ê²€ì¦ ì˜¤ë¥˜: {e}")
            return None

    def _validate_enhanced_mc_answer(self, answer: str, question: str, max_choice: int, domain: str) -> str:
        """í–¥ìƒëœ ê°ê´€ì‹ ë‹µë³€ ê²€ì¦"""
        try:
            answer_str = str(answer).strip()
            
            # ìˆ«ì ì¶”ì¶œ
            numbers = re.findall(r'\b(\d+)\b', answer_str)
            
            for num_str in numbers:
                try:
                    num = int(num_str)
                    if 1 <= num <= max_choice:
                        return str(num)
                except ValueError:
                    continue
            
            # ê²€ì¦ëœ íŒ¨í„´ìœ¼ë¡œ í´ë°±
            return self.model_handler.get_verified_mc_answer(question, max_choice, domain)
            
        except Exception:
            return "2"

    def _validate_enhanced_subjective_answer(self, answer: str, question: str, domain: str, question_id: str) -> str:
        """í–¥ìƒëœ ì£¼ê´€ì‹ ë‹µë³€ ê²€ì¦"""
        try:
            if not answer:
                return None

            answer = str(answer).strip()
            
            # 1ë‹¨ê³„: ê¸°ë³¸ ìœ íš¨ì„± ê²€ì‚¬
            if len(answer) < 25:
                return None
            
            # 2ë‹¨ê³„: í•œêµ­ì–´ ë¹„ìœ¨ ê²€ì‚¬
            korean_chars = len(re.findall(r'[ê°€-í£]', answer))
            total_chars = len(re.sub(r'[^\wê°€-í£]', '', answer))
            
            if total_chars == 0:
                return None
                
            korean_ratio = korean_chars / total_chars
            if korean_ratio < 0.7:  # ë” ì—„ê²©í•œ ê¸°ì¤€
                return None
            
            # 3ë‹¨ê³„: ì˜ì–´ ì»¨í…ì¸  ê²€ì‚¬
            if self.data_processor.detect_english_response(answer):
                return None
            
            # 4ë‹¨ê³„: ì¤‘ë³µ ê²€ì‚¬
            if self.learning.is_answer_duplicate(answer, question_id, domain, threshold=0.75):
                return None
            
            # 5ë‹¨ê³„: ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œ ê²€ì‚¬
            professional_keywords = [
                "ë²•", "ê·œì •", "ì¡°ì¹˜", "ê´€ë¦¬", "ë³´ì•ˆ", "ë°©ì•ˆ", "ì ˆì°¨", "ê¸°ì¤€", "ì •ì±…", 
                "ì²´ê³„", "ì‹œìŠ¤í…œ", "í†µì œ", "íŠ¹ì§•", "ì§€í‘œ", "íƒì§€", "ëŒ€ì‘", "ê¸°ê´€", 
                "ìœ„ì›íšŒ", "ì—…ë¬´", "ë‹´ë‹¹", "ê¶Œí•œ", "ì˜ë¬´", "ì›ì¹™", "ë¹„ìœ¨", "í¼ì„¼íŠ¸"
            ]
            
            keyword_count = sum(1 for keyword in professional_keywords if keyword in answer)
            if keyword_count < 3:
                return None
            
            # 6ë‹¨ê³„: ë¬¸ì¥ ì •ë¦¬ ë° ë§ˆë¬´ë¦¬
            return self._finalize_subjective_answer(answer, question, domain)
            
        except Exception as e:
            print(f"ì£¼ê´€ì‹ ë‹µë³€ ê²€ì¦ ì˜¤ë¥˜: {e}")
            return None

    def _finalize_subjective_answer(self, answer: str, question: str, domain: str) -> str:
        """ì£¼ê´€ì‹ ë‹µë³€ ìµœì¢… ì •ë¦¬"""
        try:
            if not answer:
                return None

            answer = answer.strip()
            
            # ê¸¸ì´ ì œí•œ (ë„ë©”ì¸ë³„)
            max_lengths = {
                "ì‚¬ì´ë²„ë³´ì•ˆ": 600,
                "ì „ìê¸ˆìœµ": 550,
                "ê°œì¸ì •ë³´ë³´í˜¸": 550,
                "ì •ë³´ë³´ì•ˆ": 500,
                "ìœ„í—˜ê´€ë¦¬": 450,
                "ê¸ˆìœµíˆ¬ì": 400,
                "ì •ë³´í†µì‹ ": 400
            }
            
            max_length = max_lengths.get(domain, 500)
            
            if len(answer) > max_length:
                sentences = re.split(r'[.!?]', answer)
                truncated_sentences = []
                current_length = 0
                
                for sentence in sentences:
                    sentence = sentence.strip()
                    if sentence and current_length + len(sentence) + 2 <= max_length:
                        truncated_sentences.append(sentence)
                        current_length += len(sentence) + 2
                    else:
                        break
                
                if truncated_sentences:
                    answer = ". ".join(truncated_sentences)
                    if not answer.endswith('.'):
                        answer += "."
                else:
                    answer = answer[:max_length-3] + "..."
            
            # ë¬¸ì¥ ë§ˆë¬´ë¦¬ í™•ì¸ ë° ìˆ˜ì •
            if answer and not answer.endswith((".", "ë‹¤", "ìš”", "í•¨", "ë‹ˆë‹¤", "ìŠµë‹ˆë‹¤")):
                if answer.endswith("ë‹ˆ"):
                    answer += "ë‹¤."
                elif answer.endswith("ìŠµ"):
                    answer += "ë‹ˆë‹¤."
                elif answer.endswith(("í•´ì•¼", "í•„ìš”", "ìˆìŒ")):
                    answer += "."
                else:
                    answer += "."

            return answer
            
        except Exception as e:
            print(f"ì£¼ê´€ì‹ ë‹µë³€ ì •ë¦¬ ì˜¤ë¥˜: {e}")
            return answer

    def _get_enhanced_fallback_answer(self, question_type: str, question: str, max_choice: int, domain: str) -> str:
        """í–¥ìƒëœ í´ë°± ë‹µë³€"""
        try:
            if question_type == "multiple_choice":
                # ê²€ì¦ëœ íŒ¨í„´ ë§¤ì¹­ ì‹œë„
                verified_answer = self.model_handler.get_verified_mc_answer(question, max_choice, domain)
                if verified_answer:
                    return verified_answer
                    
                # ë„ë©”ì¸ë³„ í†µê³„ ê¸°ë°˜ ë‹µë³€
                domain_defaults = {
                    "ê¸ˆìœµíˆ¬ì": "1",
                    "ìœ„í—˜ê´€ë¦¬": "2",
                    "ê°œì¸ì •ë³´ë³´í˜¸": "2", 
                    "ì „ìê¸ˆìœµ": "4",
                    "ì •ë³´í†µì‹ ": "2",
                    "ì •ë³´ë³´ì•ˆ": "2",
                    "ì‚¬ì´ë²„ë³´ì•ˆ": "5"
                }
                return domain_defaults.get(domain, "2")
            else:
                # ë„ë©”ì¸ë³„ ì „ë¬¸ ë‹µë³€
                domain_answers = {
                    "ì‚¬ì´ë²„ë³´ì•ˆ": "ì‚¬ì´ë²„ë³´ì•ˆ ìœ„í˜‘ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¤ì¸µ ë°©ì–´ì²´ê³„ë¥¼ êµ¬ì¶•í•˜ê³  ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ ìš´ì˜í•˜ë©°, ì¹¨ì…íƒì§€ ë° ë°©ì§€ ì‹œìŠ¤í…œì„ í†µí•´ ì¢…í•©ì ì¸ ë³´ì•ˆ ê´€ë¦¬ë¥¼ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤. ì •ê¸°ì ì¸ ë³´ì•ˆêµìœ¡ê³¼ ì·¨ì•½ì  ì ê²€ì„ í†µí•´ ì§€ì†ì ì¸ ë³´ì•ˆ ìˆ˜ì¤€ í–¥ìƒì„ ë„ëª¨í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
                    "ì „ìê¸ˆìœµ": "ì „ìê¸ˆìœµê±°ë˜ë²•ì— ë”°ë¼ ì „ìê¸ˆìœµì—…ìëŠ” ì´ìš©ìì˜ ê±°ë˜ ì•ˆì „ì„± í™•ë³´ë¥¼ ìœ„í•œ ë³´ì•ˆì¡°ì¹˜ë¥¼ ì‹œí–‰í•˜ê³ , ì ‘ê·¼ë§¤ì²´ì˜ ì•ˆì „í•œ ê´€ë¦¬ë¥¼ í†µí•´ ì•ˆì „í•œ ì „ìê¸ˆìœµì„œë¹„ìŠ¤ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. ë¶„ìŸ ë°œìƒ ì‹œì—ëŠ” ì „ìê¸ˆìœµë¶„ìŸì¡°ì •ìœ„ì›íšŒë¥¼ í†µí•´ ê³µì •í•˜ê³  ì‹ ì†í•œ í•´ê²°ì„ ë„ëª¨í•´ì•¼ í•©ë‹ˆë‹¤.",
                    "ê°œì¸ì •ë³´ë³´í˜¸": "ê°œì¸ì •ë³´ë³´í˜¸ë²•ì— ë”°ë¼ ê°œì¸ì •ë³´ ì²˜ë¦¬ ì‹œ ìˆ˜ì§‘ ìµœì†Œí™”, ëª©ì  ì œí•œ, ì •ë³´ì£¼ì²´ ê¶Œë¦¬ ë³´ì¥ì˜ ì›ì¹™ì„ ì¤€ìˆ˜í•´ì•¼ í•˜ë©°, ê°œì¸ì •ë³´ë³´í˜¸ ê´€ë¦¬ì²´ê³„ë¥¼ êµ¬ì¶•í•˜ì—¬ ì²´ê³„ì ì´ê³  ì•ˆì „í•œ ê°œì¸ì •ë³´ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤. íŠ¹íˆ ë§Œ 14ì„¸ ë¯¸ë§Œ ì•„ë™ì˜ ê°œì¸ì •ë³´ ì²˜ë¦¬ì—ëŠ” ë²•ì •ëŒ€ë¦¬ì¸ì˜ ë™ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                    "ì •ë³´ë³´ì•ˆ": "ì •ë³´ë³´ì•ˆê´€ë¦¬ì²´ê³„(ISMS)ë¥¼ êµ¬ì¶•í•˜ì—¬ ë³´ì•ˆì •ì±… ìˆ˜ë¦½, ìœ„í—˜ë¶„ì„, ë³´ì•ˆëŒ€ì±… êµ¬í˜„, ì‚¬í›„ê´€ë¦¬ì˜ ì ˆì°¨ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ìš´ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ì •ë³´ë³´í˜¸ì˜ 3ëŒ€ ìš”ì†Œì¸ ê¸°ë°€ì„±, ë¬´ê²°ì„±, ê°€ìš©ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ê¸°ìˆ ì , ê´€ë¦¬ì , ë¬¼ë¦¬ì  ë³´ì•ˆëŒ€ì±…ì„ í†µí•©ì ìœ¼ë¡œ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤.",
                    "ì •ë³´í†µì‹ ": "ì •ë³´í†µì‹ ê¸°ë°˜ ë³´í˜¸ë²•ì— ë”°ë¼ ì§‘ì ëœ ì •ë³´í†µì‹ ì‹œì„¤ì˜ ë³´í˜¸ë¥¼ ìœ„í•œ ì²´ê³„ì ì¸ ê´€ë¦¬ ë°©ì•ˆì„ ìˆ˜ë¦½í•˜ê³  ì§€ì†ì ìœ¼ë¡œ ìš´ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ì •ë³´í†µì‹ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ë°œìƒ ì‹œì—ëŠ” ê´€ë ¨ ê¸°ê´€ì— ì‹ ì†í•˜ê²Œ ë³´ê³ í•˜ê³  ì‘ê¸‰ì¡°ì¹˜ë¥¼ ì·¨í•´ì•¼ í•©ë‹ˆë‹¤.",
                    "ìœ„í—˜ê´€ë¦¬": "ìœ„í—˜ê´€ë¦¬ ì²´ê³„ë¥¼ êµ¬ì¶•í•˜ì—¬ ìœ„í—˜ ì‹ë³„, í‰ê°€, ëŒ€ì‘, ëª¨ë‹ˆí„°ë§ì˜ ë‹¨ê³„ë³„ ì ˆì°¨ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤. ìœ„í—˜ì„ ë‹¨ìˆœíˆ ìˆ˜ìš©í•˜ê¸°ë³´ë‹¤ëŠ” ìœ„í—˜ íšŒí”¼, ê°ì†Œ, ì „ê°€ ë“±ì˜ ì ê·¹ì ì¸ ëŒ€ì‘ ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
                    "ê¸ˆìœµíˆ¬ì": "ìë³¸ì‹œì¥ë²•ì— ë”°ë¼ ê¸ˆìœµíˆ¬ìì—…ì˜ êµ¬ë¶„ê³¼ íˆ¬ìì ë³´í˜¸ë¥¼ ìœ„í•œ ì í•©ì„± ì›ì¹™ì„ ì¤€ìˆ˜í•´ì•¼ í•˜ë©°, íˆ¬ììì˜ íˆ¬ìê²½í—˜ê³¼ ì¬ì‚°ìƒí™©ì— ì í•©í•œ ê¸ˆìœµìƒí’ˆì„ ê¶Œìœ í•˜ëŠ” ì²´ê³„ì ì¸ ì—…ë¬´ ìˆ˜í–‰ì´ í•„ìš”í•©ë‹ˆë‹¤."
                }
                return domain_answers.get(domain, "ê´€ë ¨ ë²•ë ¹ê³¼ ê·œì •ì— ë”°ë¼ ì²´ê³„ì ì´ê³  ì „ë¬¸ì ì¸ ê´€ë¦¬ ë°©ì•ˆì„ ìˆ˜ë¦½í•˜ì—¬ ì§€ì†ì ìœ¼ë¡œ ìš´ì˜í•´ì•¼ í•©ë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"í–¥ìƒëœ í´ë°± ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            if question_type == "multiple_choice":
                return "2"
            else:
                return "ê´€ë ¨ ë²•ë ¹ê³¼ ê·œì •ì— ë”°ë¼ ì²´ê³„ì ì¸ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."

    def _update_accuracy_tracking(self, question_type: str, success: bool):
        """ì •í™•ë„ ì¶”ì  ì—…ë°ì´íŠ¸"""
        try:
            if question_type == "multiple_choice":
                self.accuracy_tracking["mc_total"] += 1
                if success:
                    self.accuracy_tracking["mc_correct"] += 1
            else:
                self.accuracy_tracking["subjective_total"] += 1
                if success:
                    self.accuracy_tracking["subjective_valid"] += 1
        except Exception as e:
            print(f"ì •í™•ë„ ì¶”ì  ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")

    def _update_domain_performance(self, domain: str, success: bool):
        """ë„ë©”ì¸ ì„±ëŠ¥ ì—…ë°ì´íŠ¸"""
        if domain not in self.domain_performance:
            self.domain_performance[domain] = {"total": 0, "success": 0}
        
        self.domain_performance[domain]["total"] += 1
        if success:
            self.domain_performance[domain]["success"] += 1

    def _handle_processing_error(self, error: Exception, question_id: str, question: str, context: dict) -> str:
        """ì²˜ë¦¬ ì˜¤ë¥˜ í•¸ë“¤ë§"""
        try:
            domain = context.get('domain', 'unknown')
            question_type = context.get('question_type', 'unknown')
            max_choice = context.get('max_choice', 5)
            
            error_msg = str(error)
            print(f"ì§ˆë¬¸ ì²˜ë¦¬ ì˜¤ë¥˜ ({question_id}): {error_msg}")
            
            self.failed_processing += 1
            self._update_domain_performance(domain, False)
            self._update_accuracy_tracking(question_type, False)
            
            return self._get_enhanced_fallback_answer(question_type, question, max_choice, domain)
        except Exception:
            return "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def execute_inference(self, test_file: str = None, submission_file: str = None, 
                         output_file: str = None) -> Dict:
        """ì¶”ë¡  ì‹¤í–‰"""
        try:
            test_file = Path(test_file) if test_file else DEFAULT_FILES["test_file"]
            submission_file = Path(submission_file) if submission_file else DEFAULT_FILES["submission_file"]
            output_file = Path(output_file) if output_file else DEFAULT_FILES["output_file"]

            test_df = pd.read_csv(test_file, encoding=FILE_VALIDATION["encoding"])
            submission_df = pd.read_csv(submission_file, encoding=FILE_VALIDATION["encoding"])
            
            return self.execute_inference_with_data(test_df, submission_df, output_file)
        except Exception as e:
            print(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}

    def execute_inference_with_data(self, test_df: pd.DataFrame, submission_df: pd.DataFrame, 
                                   output_file: str = None) -> Dict:
        """ë°ì´í„°ì™€ í•¨ê»˜ ì¶”ë¡  ì‹¤í–‰"""
        try:
            output_file = Path(output_file) if output_file else DEFAULT_FILES["output_file"]
            
            answers = []
            self.total_questions = len(test_df)

            with tqdm(
                total=self.total_questions, 
                desc="ì¶”ë¡  ì§„í–‰", 
                unit="ë¬¸í•­",
                ncols=90,
                bar_format='{desc}: {percentage:3.1f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] ì„±ê³µë¥ : {postfix}'
            ) as pbar:
                for question_idx, (original_idx, row) in enumerate(test_df.iterrows()):
                    question = row["Question"]
                    question_id = row["ID"]

                    answer = self.process_single_question(question, question_id)
                    answers.append(answer)
                    
                    # í˜„ì¬ ì„±ê³µë¥  ê³„ì‚°
                    current_success_rate = (self.successful_processing / max(question_idx + 1, 1)) * 100
                    pbar.set_postfix_str(f"{current_success_rate:.1f}%")
                    pbar.update(1)

                    # ì£¼ê¸°ì  ì €ì¥
                    if (question_idx + 1) % MEMORY_CONFIG["pkl_save_frequency"] == 0:
                        self.learning.save_all_data()

                    # ë©”ëª¨ë¦¬ ê´€ë¦¬
                    if (question_idx + 1) % MEMORY_CONFIG["gc_frequency"] == 0:
                        try:
                            import psutil
                            if psutil.virtual_memory().percent > 85:
                                gc.collect()
                        except ImportError:
                            gc.collect()

            # ìµœì¢… ì €ì¥
            self.learning.save_all_data()
            
            # ê²°ê³¼ ì €ì¥
            submission_df["Answer"] = answers
            save_success = self._save_csv(submission_df, output_file)
            
            if not save_success:
                return {"success": False, "error": "íŒŒì¼ ì €ì¥ ì‹¤íŒ¨"}

            # ìµœì¢… ê²°ê³¼ ê³„ì‚°
            success_rate = (self.successful_processing / max(self.total_questions, 1)) * 100
            mc_accuracy = (self.accuracy_tracking["mc_correct"] / max(self.accuracy_tracking["mc_total"], 1)) * 100
            subj_valid_rate = (self.accuracy_tracking["subjective_valid"] / max(self.accuracy_tracking["subjective_total"], 1)) * 100
            
            print(f"\n=== ì¶”ë¡  ì™„ë£Œ ===")
            print(f"ì „ì²´ ë¬¸í•­: {self.total_questions}ê°œ")
            print(f"ì„±ê³µ ì²˜ë¦¬: {self.successful_processing}ê°œ")
            print(f"ì‹¤íŒ¨ ì²˜ë¦¬: {self.failed_processing}ê°œ")
            print(f"ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}%")
            print(f"ê°ê´€ì‹ ì •í™•ë„: {mc_accuracy:.1f}% ({self.accuracy_tracking['mc_correct']}/{self.accuracy_tracking['mc_total']})")
            print(f"ì£¼ê´€ì‹ ìœ íš¨ìœ¨: {subj_valid_rate:.1f}% ({self.accuracy_tracking['subjective_valid']}/{self.accuracy_tracking['subjective_total']})")
            
            # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
            target_rate = 70.0
            if success_rate >= target_rate:
                print(f"âœ“ ëª©í‘œ ë‹¬ì„±! (ëª©í‘œ: {target_rate}% ì´ìƒ)")
            else:
                improvement_needed = target_rate - success_rate
                print(f"â–³ ëª©í‘œê¹Œì§€: {improvement_needed:.1f}% ì¶”ê°€ ê°œì„  í•„ìš”")
            
            return {
                "success": True,
                "total_questions": self.total_questions,
                "successful_processing": self.successful_processing,
                "failed_processing": self.failed_processing,
                "success_rate": success_rate,
                "mc_accuracy": mc_accuracy,
                "subjective_valid_rate": subj_valid_rate,
                "domain_performance": self.domain_performance,
                "accuracy_tracking": self.accuracy_tracking,
                "learning_data": {
                    "successful_answers": len(self.learning.successful_answers),
                    "failed_answers": len(self.learning.failed_answers),
                    "domain_accuracy": self.learning.domain_accuracy
                }
            }
            
        except Exception as e:
            print(f"ì¶”ë¡  ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}

    def _save_csv(self, df: pd.DataFrame, filepath: Path) -> bool:
        """CSV ì €ì¥"""
        try:
            df.to_csv(filepath, index=False, encoding=FILE_VALIDATION["encoding"])
            return True
        except PermissionError:
            print(f"íŒŒì¼ ì ‘ê·¼ ê¶Œí•œ ì˜¤ë¥˜: {filepath}")
            return False
        except Exception as e:
            print(f"CSV ì €ì¥ ì˜¤ë¥˜: {e}")
            return False

    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if hasattr(self, 'learning'):
                self.learning.save_all_data()
            
            if hasattr(self, "model_handler"):
                self.model_handler.cleanup()

            if hasattr(self, "data_processor"):
                self.data_processor.cleanup()

            if hasattr(self, "knowledge_base"):
                self.knowledge_base.cleanup()
                
            if hasattr(self, "prompt_enhancer"):
                self.prompt_enhancer.cleanup()

            gc.collect()
            print("ì¶”ë¡  ì—”ì§„ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

        except Exception as e:
            print(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì˜¤ë¥˜: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    engine = None
    try:
        print("=== ê¸ˆìœµë³´ì•ˆ AI ì¶”ë¡  ì‹œìŠ¤í…œ (ì •í™•ë„ ìµœì í™” ë²„ì „) ===")
        engine = FinancialAIInference(verbose=False)

        results = engine.execute_inference()

        if results.get("success"):
            success_rate = results.get('success_rate', 0)
            mc_accuracy = results.get('mc_accuracy', 0)
            subj_valid_rate = results.get('subjective_valid_rate', 0)
            
            print(f"\n=== ìµœì¢… ê²°ê³¼ ===")
            print(f"ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}%")
            print(f"ê°ê´€ì‹ ì •í™•ë„: {mc_accuracy:.1f}%")
            print(f"ì£¼ê´€ì‹ ìœ íš¨ìœ¨: {subj_valid_rate:.1f}%")
            
            if success_rate >= 70:
                print("ğŸ‰ ëª©í‘œ ë‹¬ì„±: 70% ì´ìƒ ì •í™•ë„ í™•ë³´!")
            elif success_rate >= 60:
                print("ğŸ“ˆ ì–‘í˜¸í•œ ì„±ëŠ¥: ì¶”ê°€ ìµœì í™”ë¡œ ëª©í‘œ ë‹¬ì„± ê°€ëŠ¥")
            else:
                print("ğŸ”§ ì¶”ê°€ ê°œì„  í•„ìš”: ì•Œê³ ë¦¬ì¦˜ ë° ë°ì´í„° ë³´ê°• ê¶Œì¥")
                
        else:
            print(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {results.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

    except KeyboardInterrupt:
        print("\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if engine:
            engine.cleanup()


if __name__ == "__main__":
    main()