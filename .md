# 대회 개발 규칙 & 환경 참조 가이드

이 문서는 AI 모델링 대회 개발 시 참조할 수 있는 핵심 규칙과 제약사항을 정리한 가이드입니다. 개발 중 의문이 생길 때 이 문서를 참조하여 규칙 위반을 방지하고 효율적인 개발을 진행할 수 있습니다.

## 핵심 개발 원칙

**허용 원칙**: 로컬 환경에서 사전 준비된 리소스만을 활용한 순수 AI 모델링  
**금지 원칙**: 외부 API 호출, 실시간 데이터 수집, 인터넷 의존성을 가진 모든 방식

## 모델 사용 규칙

**사용 가능한 모델 조건**  
2025년 8월 1일 이전에 공개된 사전 학습 모델 중에서 오픈소스 라이선스(MIT, Apache 2.0 등)를 가진 모델만 사용 가능합니다. Hugging Face의 LLaMA 2, Mistral, Qwen, SOLAR 등이 대표적인 허용 대상입니다.

**절대 금지 모델**  
OpenAI GPT 시리즈, Google Gemini, Anthropic Claude와 같은 API 기반 모델은 완전히 금지됩니다. 복수 LLM 앙상블이나 문제 유형별 다른 모델 사용도 불가능하며, 반드시 단일 LLM 모델로만 모든 문제를 해결해야 합니다.

## 데이터 사용 규칙

**허용되는 외부 데이터**  
2025년 8월 1일 이전 공식 공개된 데이터 중 비상업적 이용 허용 라이선스(CC BY-NC, CC0, CC-BY-SA 등)를 가진 데이터만 사용 가능합니다. 모든 외부 데이터는 출처와 라이선스를 명확히 증명할 수 있어야 합니다.

**데이터 증강 허용 범위**  
룰 기반 텍스트 변형이나 로컬 구동 생성 AI 모델을 활용한 데이터 생성이 허용됩니다. 모든 증강 과정은 관련 코드와 함께 제출되어야 하며, 증강에 사용되는 원천 데이터와 모델 역시 대회 규칙을 준수해야 합니다.

**금지되는 데이터**  
직접 수집한 모든 데이터(수기 작성, 웹 크롤링, 개인 수집 자료)는 사용 불가능합니다. 평가 데이터셋 정보를 활용하는 Data Leakage는 즉시 실격 사유가 됩니다.

## 개발 단계와 추론 단계의 구분

**개발 단계의 자유도**  
개발 과정에서는 자동 학습과 수동 교정을 마음껏 활용할 수 있습니다. 허용된 외부 데이터 활용, 도메인 특화 파인튜닝, 약점 분석을 통한 집중 학습, 다양한 실험과 최적화가 모두 허용됩니다.

**추론 단계의 엄격한 제약**  
최종 추론은 인터넷 연결이 차단된 오프라인 서버에서 진행됩니다. 데이터 전처리, 모델 로드, 모델 추론, 최종 출력 생성의 모든 과정이 사전 준비된 로컬 리소스만으로 동작해야 합니다.

## 성능 및 리소스 제약

**하드웨어 환경 제약**  
GPU RTX 4090 24GB VRAM, CPU 6 vCPU 41GB RAM, 디스크 40GB 환경에서 동작해야 합니다. 운영체제는 Ubuntu 22.04이며 Python 3.10, CUDA 11.8, PyTorch 2.1.0 환경을 기준으로 합니다.

**시간 제약**  
전체 평가 데이터셋에 대해 4시간 30분을 초과할 수 없으며, 이는 샘플당 약 30초 내외의 추론 시간을 의미합니다. 추론 시간은 운영진이 5번 실행한 평균 시간으로 측정됩니다.

## 답변 생성 요구사항

**필수 포함 요소**  
최종 답변은 생성형 언어 모델(LLM)에 의해 생성된 텍스트여야 합니다. 단순 룰 기반 출력이나 사전 정의된 정답 목록 선택만으로는 부족합니다.

**RAG 시스템 사용 시 주의사항**  
검색 증강 생성(RAG) 방식은 허용되지만 검색된 내용의 단순 반환은 금지됩니다. 반드시 생성 모델을 활용한 조합, 요약, 재구성 등의 가공 과정이 포함되어야 합니다.

## 주요 실격 위험 요소

**즉시 실격 사유**  
외부 API 사용 답변 생성, 실시간 웹 크롤링이나 검색 활용, 라이선스 문제가 있는 데이터 사용, 평가 데이터셋 정보의 사전 학습 활용이 해당됩니다.

**검증 실패 위험 요소**  
Private Score 재현 불가능한 코드, 지정 환경에서 실행되지 않는 의존성, 필수 파일 누락, 기술적 요구사항 위반 등이 검증 과정에서 문제가 될 수 있습니다.

## 제출 전 필수 확인사항

**모델 및 데이터 검증**  
사용 모델의 공개 날짜와 오픈소스 라이선스 확인, 모든 외부 데이터의 라이선스 검증, 완전한 오프라인 동작 가능성, 단일 LLM 사용 원칙 준수, 제한 시간 내 추론 완료 가능성을 확인해야 합니다.

**제출 파일 검증**  
추론 코드의 별도 파일 분리, 모델 가중치 파일 포함, 외부 데이터 출처 증빙자료 준비, UTF-8 인코딩 적용, 상대경로 설정을 확인해야 합니다.

이 가이드의 원칙들을 준수하면서 자동 학습과 수동 교정을 적극 활용하여 최적의 성능을 달성할 수 있습니다. 규칙 위반으로 인한 실격 위험을 방지하면서도 창의적이고 효과적인 AI 모델링이 가능합니다.